<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>dp_policy.experiments API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dp_policy.experiments</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L1-L609" class="git-link">Browse git</a>
</summary>
<pre><code class="python">import os
import pandas as pd
from tqdm import tqdm
import numpy as np
import itertools
import matplotlib.pyplot as plt

import dp_policy.config as config
from dp_policy.titlei.evaluation import \
    discrimination_treatments_join, save_treatments, load_treatments, \
    match_true, compare_treatments, misalloc_statistics
from dp_policy.titlei.mechanisms import Laplace
from dp_policy.titlei.utils import get_inputs, data, get_sppe
from dp_policy.titlei.allocators import SonnenbergAuthorizer
from dp_policy.titlei.thresholders import \
    AverageThresholder, RepeatThresholder, DummyThresholder, MOEThresholder, \
    PastThresholder


def titlei_funding(
    allocator, inputs, mechanism, sppe,
    normalize=True,
    allocator_kwargs={}, sampling_kwargs={},
    **grants_kwargs
):
    &#34;&#34;&#34;
    Returns augmented SAIPE dataframe with randomized estimates and
    true/randomized grant amounts.
    &#34;&#34;&#34;
    alloc = allocator(
        data(
            inputs, mechanism, sppe,
            sampling_kwargs=sampling_kwargs,
            **grants_kwargs
        ),
        **allocator_kwargs
    )
    return alloc.allocations(normalize=normalize)


def titlei_grid(
    inputs, mech,
    eps=list(np.logspace(-3, 10, num=10)) + [2.52], delta=[0.0],
    trials=100,
    mech_kwargs={},
    auth=False,
    allocator_kwargs={},
    sampling_kwargs={},
    verbose=True,
    print_results=[2.52, 0.1],
    plot_results=False,
    alpha=0.05,
    results=None
):
    if results is None:
        allocations = []
        thresholder = allocator_kwargs.get(&#39;thresholder&#39;)
        if verbose:
            print(f&#34;{len(eps)*len(delta)*trials} iters:&#34;)
        for trial in tqdm(range(trials), desc=&#39;trial&#39;, disable=(not verbose)):
            for d in tqdm(delta, desc=&#39;delta&#39;, leave=False, disable=True):
                for e in tqdm(eps, desc=&#39;eps&#39;, leave=False, disable=True):
                    mechanism = mech(e, d, **mech_kwargs)
                    sppe = get_sppe(os.path.join(
                        config.root,
                        &#34;data/sppe18.xlsx&#34;
                    ))
                    if thresholder is not None and isinstance(
                            thresholder, PastThresholder
                    ):
                        thresholder.set_prior_estimates(
                            mechanism,
                            sppe,
                            verbose=False
                        )
                    allocations.append(titlei_funding(
                        SonnenbergAuthorizer,
                        inputs,
                        mechanism,
                        sppe,
                        allocator_kwargs=allocator_kwargs,
                        sampling_kwargs=sampling_kwargs,
                        verbose=False,  # too noisy for a grid search
                        normalize=(not auth)
                    ))
        results = pd.concat(
            allocations, axis=0,
            keys=itertools.product(range(trials), delta, eps),
            names=[
                &#34;trial&#34;, &#34;delta&#34;, &#34;epsilon&#34;
            ] + list(allocations[-1].index.names)
        )

    if print_results:
        prefixes = [&#34;est&#34;, &#34;dp&#34;, &#34;dpest&#34;]

        for e, alloc in results.groupby(&#34;epsilon&#34;):
            if e in print_results:
                print(f&#34;--- eps={e} ---&#34;)
                data_error = alloc[&#34;est_children_eligible&#34;] \
                    - alloc[&#34;true_children_eligible&#34;]
                dp_error = alloc[&#34;dpest_children_eligible&#34;] \
                    - alloc[&#34;est_children_eligible&#34;]
                s = 0.5
                plt.scatter(
                    alloc[&#34;true_children_eligible&#34;], data_error,
                    s, label=&#34;data&#34;
                )
                plt.scatter(
                    alloc[&#34;true_children_eligible&#34;], dp_error,
                    s, label=&#34;dp&#34;
                )
                plt.legend()
                plt.xlabel(&#34;# children in poverty&#34;)
                plt.ylabel(&#34;Noise&#34;)
                plt.show()

                plt.scatter(
                    alloc[&#34;true_children_eligible&#34;],
                    data_error/alloc[&#34;true_children_eligible&#34;],
                    s, label=&#34;data&#34;
                )
                plt.scatter(
                    alloc[&#34;true_children_eligible&#34;],
                    dp_error/alloc[&#34;true_children_eligible&#34;],
                    s, label=&#34;dp&#34;
                )
                plt.legend()
                plt.xlabel(&#34;# children in poverty&#34;)
                plt.ylabel(&#34;Noise per child in poverty&#34;)
                plt.show()

        for prefix in prefixes:
            print(&#34;##&#34;, prefix)
            for e, alloc in results.groupby(&#34;epsilon&#34;):
                for grant_type in (
                    &#34;basic&#34;, &#34;concentration&#34;, &#34;targeted&#34;, &#34;total&#34;
                ):
                    if e in print_results:
                        error = alloc[f&#34;{prefix}_grant_{grant_type}&#34;] \
                            - alloc[f&#34;true_grant_{grant_type}&#34;]
                        print(f&#34;## {grant_type} grants - eps={e} ##&#34;)
                        misalloc_statistics(
                            error,
                            allocations=alloc,
                            grant_type=grant_type
                        )

            if plot_results:
                trials = len(np.unique(
                    results.index.get_level_values(&#34;trial&#34;)
                ))

                grant_type = &#34;total&#34;

                error = results[f&#34;{prefix}_grant_{grant_type}&#34;] \
                    - results[f&#34;true_grant_{grant_type}&#34;]
                print(error.shape)
                rmse = np.sqrt(error.pow(2).groupby(
                    [&#34;epsilon&#34;, &#34;trial&#34;]
                ).mean())
                print(rmse)
                mse = {
                    &#39;mean&#39;: rmse.groupby(&#34;epsilon&#34;).mean(),
                    &#39;lower&#39;: rmse.groupby(&#34;epsilon&#34;).quantile(alpha/2),
                    &#39;upper&#39;: rmse.groupby(&#34;epsilon&#34;).quantile(1-alpha/2)
                }
                eps = mse[&#39;mean&#39;].index
                plt.plot(eps, mse[&#39;mean&#39;])
                plt.fill_between(
                    eps, mse[&#39;lower&#39;], mse[&#39;upper&#39;],
                    color=&#39;gray&#39;, alpha=0.25
                )
                ax = plt.gca()
                ax.set_xscale(&#39;log&#39;)
                plt.xlabel(&#34;Epsilon&#34;)
                plt.ylabel(
                    f&#34;Avg. RMSE in {grant_type} grants over {trials} trials&#34;
                )
                plt.savefig(
                    os.path.join(
                        config.root,
                        &#34;plots/robustness/eps_sensitivity_frontier.png&#34;
                    ),
                    dpi=300
                )
                plt.show()

                # for i in range(len(eps)):
                #     e = eps[i]
                #     alloc = allocations[i][allocations[i][
                #         &#34;State Postal Code&#34;] == &#34;MI&#34;
                #     ]
                #     alloc = alloc.sort_values(f&#34;true_grant_{grant_type}&#34;)
                #     plt.scatter(
                #         range(len(alloc)),
                #         alloc[f&#34;{prefix}_grant_{grant_type}&#34;] /
                #         alloc[f&#34;{prefix}_grant_{grant_type}&#34;].sum(),
                #         s=2, alpha=0.3, label=f&#34;eps={e}&#34;
                #     )
                # plt.scatter(
                #     range(len(alloc)),
                #     alloc[f&#34;true_grant_{grant_type}&#34;] /
                #     sum(alloc[f&#34;true_grant_{grant_type}&#34;]),
                #     s=2, alpha=0.3, label=&#34;true&#34;
                # )
                # ax = plt.gca()
                # ax.legend()
                # ax.axes.xaxis.set_ticks([])
                # ax.set_yscale(&#39;log&#39;)
                # plt.xlabel(&#34;District (sorted by true alloc)&#34;)
                # plt.ylabel(&#34;Allocation as % of total&#34;)
                # plt.title(f&#34;{grant_type} grants for Michigan&#34;)
                # plt.show()

                # for i in range(len(eps)):
                #     e = eps[i]
                #     alloc = allocations[i][allocations[i][
                #         &#34;State Postal Code&#34;] == &#34;MI&#34;
                #     ]
                #     alloc[&#39;err_prop&#39;] = (
                #         alloc[f&#34;{prefix}_grant_{grant_type}&#34;] /
                #         sum(alloc[f&#34;{prefix}_grant_{grant_type}&#34;]) -
                #         alloc[f&#34;true_grant_{grant_type}&#34;] /
                #         sum(alloc[f&#34;true_grant_{grant_type}&#34;])
                #     ) * 1e6
                #     plt.scatter(
                #         alloc[f&#34;true_grant_{grant_type}&#34;] /
                #         sum(alloc[f&#34;true_grant_{grant_type}&#34;]),
                #         alloc.err_prop, s=3, alpha=0.4, label=f&#34;eps={e}&#34;
                #     )
                # ax = plt.gca()
                # ax.legend()
                # ax.set_xscale(&#39;log&#39;)
                # ax.set_yscale(&#39;log&#39;)
                # plt.xlabel(&#34;True allocation as % of total&#34;)
                # plt.ylabel(&#34;Misallocation per million as % of total&#34;)
                # plt.title(f&#34;{grant_type} grants for Michigan&#34;)
                # plt.show()

    return results


class Experiment:
    def __init__(
        self,
        name,
        baseline=&#34;cached&#34;,
        year=2021,
        trials=1000,
        eps=[0.1],
        delta=[0.0]
    ):
        self.name = name
        self.trials = trials
        self.eps = eps
        self.delta = delta
        self.saipe = get_inputs(year)

        if str(baseline) == &#34;cached&#34;:
            print(&#34;Using cached baseline...&#34;)
            try:
                self.baseline = load_treatments(&#34;baseline&#34;)[&#39;baseline&#39;]
            except FileNotFoundError:
                print(&#34;[WARN] Could not find cached baseline, generating.&#34;)
                self._generate_baseline()
        elif baseline is None:
            print(&#34;Generating baseline...&#34;)
            self._generate_baseline()
        else:
            print(&#34;Using given baseline...&#34;)
            self.baseline = baseline

    def _generate_baseline(self):
        self.baseline = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps, delta=self.delta,
            trials=self.trials,
            print_results=False,
            allocator_kwargs={&#39;verbose&#39;: False}
        )
        save_treatments({&#39;baseline&#39;: self.baseline}, &#34;baseline&#34;)
        discrimination_treatments_join(&#34;baseline&#34;)

    def run(self):
        treatments = self._get_treatments()
        save_treatments(treatments, self.name)
        self.discrimination_join()

    def _get_treatments(self):
        raise NotImplementedError

    def discrimination_join(self, **join_kwargs):
        discrimination_treatments_join(self.name, **join_kwargs)

    def plot(self, **kwargs):
        treatments = load_treatments(self.name)
        compare_treatments(treatments, experiment_name=self.name, **kwargs)

    @staticmethod
    def get_experiment(name, *args, **kwargs):
        experiments = {
            &#39;baseline&#39;: Baseline,
            &#39;hold_harmless&#39;: HoldHarmless,
            &#39;post_processing&#39;: PostProcessing,
            &#39;thresholds&#39;: Thresholds,
            &#39;epsilon&#39;: Epsilon,
            &#39;moving_average&#39;: MovingAverage,
            &#39;budget&#39;: Budget,
            &#39;sampling&#39;: Sampling
        }
        Exp = experiments.get(name)
        if Exp is None:
            raise ValueError(f&#34;{name} not a supported experiment name.&#34;)
        return Exp(name, *args, **kwargs)


class Baseline(Experiment):
    def _get_treatments(self):
        return {
            &#39;baseline&#39;: self.baseline
        }


class HoldHarmless(Experiment):
    def _get_treatments(self):
        hold_harmless = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps, delta=self.delta,
            trials=self.trials, print_results=False,
            allocator_kwargs={&#39;hold_harmless&#39;: True}
        )
        state_minimum = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps, delta=self.delta,
            trials=self.trials, print_results=False,
            allocator_kwargs={&#39;state_minimum&#39;: True}
        )
        both = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps, delta=self.delta,
            trials=self.trials, print_results=False,
            allocator_kwargs={
                &#39;hold_harmless&#39;: True,
                &#39;state_minimum&#39;: True
            }
        )
        # ground truths are the same
        match_true(self.baseline, [hold_harmless, state_minimum, both])

        # save treatments to file for later
        return {
            &#39;No provisions (baseline)&#39;: self.baseline,
            &#39;Hold harmless only&#39;: hold_harmless,
            &#39;State minimum only&#39;: state_minimum,
            &#39;Both provisions&#39;: both
        }


class PostProcessing(Experiment):
    def _get_treatments(self):
        none = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            mech_kwargs=dict(
                clip=False,
                round=False
            ),
            print_results=False
        )
        clipping = self.baseline
        rounding = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            mech_kwargs=dict(
                clip=True,
                round=True
            ),
            print_results=False
        )
        match_true(self.baseline, [none, rounding])
        return {
            &#39;None&#39;: none,
            &#39;Clipping (baseline)&#39;: clipping,
            &#39;Clipping + Rounding&#39;: rounding
        }


class MovingAverage(Experiment):
    def __init__(self, name, truth=&#34;average&#34;, **kwargs):
        if truth != &#34;average&#34;:
            raise Exception(
                &#34;Not supporting truth values other than `average`.&#34;
            )
        self.truth = truth
        super().__init__(f&#34;{name}_truth={truth}&#34;, **kwargs)

    def _get_treatments(self):
        single_year = self.baseline
        averaged = [
            titlei_grid(
                get_inputs(2021, avg_lag=i+1),
                Laplace,
                eps=self.eps,
                delta=self.delta,
                trials=self.trials,
                print_results=False
            )
            for i in range(4)
        ]
        match_true(averaged[-1], [single_year] + averaged[:-1])
        return {
            &#39;Lag 0&#39;: single_year,
            **{f&#34;Lag {i+1}&#34;: a for i, a in enumerate(averaged)}
        }


class Thresholds(Experiment):
    def _get_treatments(self):
        # hard threshold
        hard = self.baseline

        # use average
        averaged = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: AverageThresholder(2021, 4)
            },
            print_results=False
        )

        # must be ineligible 2x in a row
        repeat2 = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: RepeatThresholder(2021, 1)
            },
            print_results=False
        )

        # must be ineligible 3x in a row
        repeat3 = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: RepeatThresholder(2021, 2)
            },
            print_results=False
        )

        # no threshold
        none = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: DummyThresholder()
            },
            print_results=False
        )

        # moe
        moe_01 = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: MOEThresholder(alpha=0.1)
            },
            print_results=False
        )

        match_true(hard, [averaged, repeat2, repeat3, none, moe_01])
        return {
            &#39;None&#39;: none,
            &#39;Hard (baseline)&#39;: hard,
            &#39;Averaged&#39;: averaged,
            &#39;Repeated years (2)&#39;: repeat2,
            &#39;Repeated years (3)&#39;: repeat3,
            &#39;Margin of error (90%)&#39;: moe_01
        }


class Budget(Experiment):
    def _get_treatments(self):
        if len(self.eps) &gt; 0:
            print(&#34;[WARN] Using first value of epsilon for budget calcs.&#34;)

        e = self.eps[0]
        alpha = 0.05
        test = self.baseline.loc[pd.IndexSlice[:, 0.0, e, :, :], :]

        budgets = {
            &#34;Biden proposal&#34;: 2e10
        }
        for name, prefixes in {
            &#34;+ loss&#34;: (&#34;dpest&#34;, &#34;true&#34;),
            # &#34;+ marginal loss (DP)&#34;: (&#34;dpest&#34;, &#34;est&#34;),
            # &#34;+ loss (data error)&#34;: (&#34;est&#34;, &#34;true&#34;)
        }.items():
            error = test[f&#34;{prefixes[1]}_grant_total&#34;] \
                - test[f&#34;{prefixes[0]}_grant_total&#34;]
            err_grouped = error.groupby(
                [&#34;State FIPS Code&#34;, &#34;District ID&#34;]
            )
            exp_error = err_grouped.mean()

            budgets[name] = exp_error[exp_error &lt; 0].abs().sum()

            if prefixes == (&#34;dpest&#34;, &#34;true&#34;):
                # how much money to remove alpha quantile loss?
                quantile = err_grouped.quantile(alpha)
                budgets[f&#34;+ {(alpha)*100}% quant. loss&#34;] = \
                    quantile[quantile &lt; 0].abs().sum()

                # how much money to cover all misallocated dollars?
                # budgets[f&#34;+ exp. misalloc.&#34;] = exp_error.abs().sum()

        budgets = {&#34;{} (${:.1e})&#34;.format(k, v): v for k, v in budgets.items()}

        usual_budget = self.saipe[&#34;official_total_alloc&#34;]\
            .groupby([&#34;State FIPS Code&#34;, &#34;District ID&#34;]).first().sum()
        print(&#34;baseline budget: {:.1e}&#34;.format(usual_budget))
        print(budgets)

        treatments = {
            name: titlei_grid(
                self.saipe, Laplace,
                eps=[e], delta=self.delta,
                trials=self.trials, print_results=False,
                allocator_kwargs={
                    &#39;appropriation&#39;: round(budget + usual_budget, 2)
                }
            ) for name, budget in budgets.items()
        }
        match_true(self.baseline, list(treatments.values()))
        treatments[&#34;FY2019 appropriation (baseline)&#34;] = test

        return treatments


class Epsilon(Experiment):
    def _get_treatments(self):
        return {
            e: titlei_grid(
                self.saipe, Laplace,
                eps=[e], delta=self.delta,
                trials=self.trials, print_results=False
            ) if e not in self.eps
            else self.baseline.loc[pd.IndexSlice[:, 0.0, e, :, :], :].copy()
            for e in [1e-3, 1e-2, 1e-1, 1, 10, 30]
        }

    def discrimination_join(self):
        return super().discrimination_join(epsilon=None)

    def plot(self):
        return super().plot(epsilon=None)


class Sampling(Experiment):
    def _get_treatments(self):
        gaussian = {
            f&#34;Gaussian ({m})&#34;: titlei_grid(
                self.saipe, Laplace,
                eps=self.eps, delta=self.delta,
                trials=self.trials, print_results=False,
                sampling_kwargs=dict(
                    multiplier=m,
                    distribution=&#34;gaussian&#34;
                )
            )
            for m in [0.5, 0.75, 1, 1.5]
        }
        laplace = {
            f&#34;Laplace ({m})&#34;: titlei_grid(
                self.saipe, Laplace,
                eps=self.eps, delta=self.delta,
                trials=self.trials, print_results=False,
                sampling_kwargs=dict(
                    multiplier=m,
                    distribution=&#34;laplace&#34;
                )
            )
            for m in [0.5, 1, 1.5]
        }
        return {
            **gaussian,
            **laplace
        }</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dp_policy.experiments.titlei_funding"><code class="name flex">
<span>def <span class="ident">titlei_funding</span></span>(<span>allocator, inputs, mechanism, sppe, normalize=True, allocator_kwargs={}, sampling_kwargs={}, **grants_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns augmented SAIPE dataframe with randomized estimates and
true/randomized grant amounts.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L20-L38" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def titlei_funding(
    allocator, inputs, mechanism, sppe,
    normalize=True,
    allocator_kwargs={}, sampling_kwargs={},
    **grants_kwargs
):
    &#34;&#34;&#34;
    Returns augmented SAIPE dataframe with randomized estimates and
    true/randomized grant amounts.
    &#34;&#34;&#34;
    alloc = allocator(
        data(
            inputs, mechanism, sppe,
            sampling_kwargs=sampling_kwargs,
            **grants_kwargs
        ),
        **allocator_kwargs
    )
    return alloc.allocations(normalize=normalize)</code></pre>
</details>
</dd>
<dt id="dp_policy.experiments.titlei_grid"><code class="name flex">
<span>def <span class="ident">titlei_grid</span></span>(<span>inputs, mech, eps=[0.001, 0.027825594022071243, 0.774263682681127, 21.54434690031882, 599.4842503189409, 16681.005372000593, 464158.8833612772, 12915496.650148828, 359381366.3804626, 10000000000.0, 2.52], delta=[0.0], trials=100, mech_kwargs={}, auth=False, allocator_kwargs={}, sampling_kwargs={}, verbose=True, print_results=[2.52, 0.1], plot_results=False, alpha=0.05, results=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L41-L241" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def titlei_grid(
    inputs, mech,
    eps=list(np.logspace(-3, 10, num=10)) + [2.52], delta=[0.0],
    trials=100,
    mech_kwargs={},
    auth=False,
    allocator_kwargs={},
    sampling_kwargs={},
    verbose=True,
    print_results=[2.52, 0.1],
    plot_results=False,
    alpha=0.05,
    results=None
):
    if results is None:
        allocations = []
        thresholder = allocator_kwargs.get(&#39;thresholder&#39;)
        if verbose:
            print(f&#34;{len(eps)*len(delta)*trials} iters:&#34;)
        for trial in tqdm(range(trials), desc=&#39;trial&#39;, disable=(not verbose)):
            for d in tqdm(delta, desc=&#39;delta&#39;, leave=False, disable=True):
                for e in tqdm(eps, desc=&#39;eps&#39;, leave=False, disable=True):
                    mechanism = mech(e, d, **mech_kwargs)
                    sppe = get_sppe(os.path.join(
                        config.root,
                        &#34;data/sppe18.xlsx&#34;
                    ))
                    if thresholder is not None and isinstance(
                            thresholder, PastThresholder
                    ):
                        thresholder.set_prior_estimates(
                            mechanism,
                            sppe,
                            verbose=False
                        )
                    allocations.append(titlei_funding(
                        SonnenbergAuthorizer,
                        inputs,
                        mechanism,
                        sppe,
                        allocator_kwargs=allocator_kwargs,
                        sampling_kwargs=sampling_kwargs,
                        verbose=False,  # too noisy for a grid search
                        normalize=(not auth)
                    ))
        results = pd.concat(
            allocations, axis=0,
            keys=itertools.product(range(trials), delta, eps),
            names=[
                &#34;trial&#34;, &#34;delta&#34;, &#34;epsilon&#34;
            ] + list(allocations[-1].index.names)
        )

    if print_results:
        prefixes = [&#34;est&#34;, &#34;dp&#34;, &#34;dpest&#34;]

        for e, alloc in results.groupby(&#34;epsilon&#34;):
            if e in print_results:
                print(f&#34;--- eps={e} ---&#34;)
                data_error = alloc[&#34;est_children_eligible&#34;] \
                    - alloc[&#34;true_children_eligible&#34;]
                dp_error = alloc[&#34;dpest_children_eligible&#34;] \
                    - alloc[&#34;est_children_eligible&#34;]
                s = 0.5
                plt.scatter(
                    alloc[&#34;true_children_eligible&#34;], data_error,
                    s, label=&#34;data&#34;
                )
                plt.scatter(
                    alloc[&#34;true_children_eligible&#34;], dp_error,
                    s, label=&#34;dp&#34;
                )
                plt.legend()
                plt.xlabel(&#34;# children in poverty&#34;)
                plt.ylabel(&#34;Noise&#34;)
                plt.show()

                plt.scatter(
                    alloc[&#34;true_children_eligible&#34;],
                    data_error/alloc[&#34;true_children_eligible&#34;],
                    s, label=&#34;data&#34;
                )
                plt.scatter(
                    alloc[&#34;true_children_eligible&#34;],
                    dp_error/alloc[&#34;true_children_eligible&#34;],
                    s, label=&#34;dp&#34;
                )
                plt.legend()
                plt.xlabel(&#34;# children in poverty&#34;)
                plt.ylabel(&#34;Noise per child in poverty&#34;)
                plt.show()

        for prefix in prefixes:
            print(&#34;##&#34;, prefix)
            for e, alloc in results.groupby(&#34;epsilon&#34;):
                for grant_type in (
                    &#34;basic&#34;, &#34;concentration&#34;, &#34;targeted&#34;, &#34;total&#34;
                ):
                    if e in print_results:
                        error = alloc[f&#34;{prefix}_grant_{grant_type}&#34;] \
                            - alloc[f&#34;true_grant_{grant_type}&#34;]
                        print(f&#34;## {grant_type} grants - eps={e} ##&#34;)
                        misalloc_statistics(
                            error,
                            allocations=alloc,
                            grant_type=grant_type
                        )

            if plot_results:
                trials = len(np.unique(
                    results.index.get_level_values(&#34;trial&#34;)
                ))

                grant_type = &#34;total&#34;

                error = results[f&#34;{prefix}_grant_{grant_type}&#34;] \
                    - results[f&#34;true_grant_{grant_type}&#34;]
                print(error.shape)
                rmse = np.sqrt(error.pow(2).groupby(
                    [&#34;epsilon&#34;, &#34;trial&#34;]
                ).mean())
                print(rmse)
                mse = {
                    &#39;mean&#39;: rmse.groupby(&#34;epsilon&#34;).mean(),
                    &#39;lower&#39;: rmse.groupby(&#34;epsilon&#34;).quantile(alpha/2),
                    &#39;upper&#39;: rmse.groupby(&#34;epsilon&#34;).quantile(1-alpha/2)
                }
                eps = mse[&#39;mean&#39;].index
                plt.plot(eps, mse[&#39;mean&#39;])
                plt.fill_between(
                    eps, mse[&#39;lower&#39;], mse[&#39;upper&#39;],
                    color=&#39;gray&#39;, alpha=0.25
                )
                ax = plt.gca()
                ax.set_xscale(&#39;log&#39;)
                plt.xlabel(&#34;Epsilon&#34;)
                plt.ylabel(
                    f&#34;Avg. RMSE in {grant_type} grants over {trials} trials&#34;
                )
                plt.savefig(
                    os.path.join(
                        config.root,
                        &#34;plots/robustness/eps_sensitivity_frontier.png&#34;
                    ),
                    dpi=300
                )
                plt.show()

                # for i in range(len(eps)):
                #     e = eps[i]
                #     alloc = allocations[i][allocations[i][
                #         &#34;State Postal Code&#34;] == &#34;MI&#34;
                #     ]
                #     alloc = alloc.sort_values(f&#34;true_grant_{grant_type}&#34;)
                #     plt.scatter(
                #         range(len(alloc)),
                #         alloc[f&#34;{prefix}_grant_{grant_type}&#34;] /
                #         alloc[f&#34;{prefix}_grant_{grant_type}&#34;].sum(),
                #         s=2, alpha=0.3, label=f&#34;eps={e}&#34;
                #     )
                # plt.scatter(
                #     range(len(alloc)),
                #     alloc[f&#34;true_grant_{grant_type}&#34;] /
                #     sum(alloc[f&#34;true_grant_{grant_type}&#34;]),
                #     s=2, alpha=0.3, label=&#34;true&#34;
                # )
                # ax = plt.gca()
                # ax.legend()
                # ax.axes.xaxis.set_ticks([])
                # ax.set_yscale(&#39;log&#39;)
                # plt.xlabel(&#34;District (sorted by true alloc)&#34;)
                # plt.ylabel(&#34;Allocation as % of total&#34;)
                # plt.title(f&#34;{grant_type} grants for Michigan&#34;)
                # plt.show()

                # for i in range(len(eps)):
                #     e = eps[i]
                #     alloc = allocations[i][allocations[i][
                #         &#34;State Postal Code&#34;] == &#34;MI&#34;
                #     ]
                #     alloc[&#39;err_prop&#39;] = (
                #         alloc[f&#34;{prefix}_grant_{grant_type}&#34;] /
                #         sum(alloc[f&#34;{prefix}_grant_{grant_type}&#34;]) -
                #         alloc[f&#34;true_grant_{grant_type}&#34;] /
                #         sum(alloc[f&#34;true_grant_{grant_type}&#34;])
                #     ) * 1e6
                #     plt.scatter(
                #         alloc[f&#34;true_grant_{grant_type}&#34;] /
                #         sum(alloc[f&#34;true_grant_{grant_type}&#34;]),
                #         alloc.err_prop, s=3, alpha=0.4, label=f&#34;eps={e}&#34;
                #     )
                # ax = plt.gca()
                # ax.legend()
                # ax.set_xscale(&#39;log&#39;)
                # ax.set_yscale(&#39;log&#39;)
                # plt.xlabel(&#34;True allocation as % of total&#34;)
                # plt.ylabel(&#34;Misallocation per million as % of total&#34;)
                # plt.title(f&#34;{grant_type} grants for Michigan&#34;)
                # plt.show()

    return results</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dp_policy.experiments.Baseline"><code class="flex name class">
<span>class <span class="ident">Baseline</span></span>
<span>(</span><span>name, baseline='cached', year=2021, trials=1000, eps=[0.1], delta=[0.0])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L318-L322" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Baseline(Experiment):
    def _get_treatments(self):
        return {
            &#39;baseline&#39;: self.baseline
        }</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></li>
</ul>
</dd>
<dt id="dp_policy.experiments.Budget"><code class="flex name class">
<span>class <span class="ident">Budget</span></span>
<span>(</span><span>name, baseline='cached', year=2021, trials=1000, eps=[0.1], delta=[0.0])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L503-L558" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Budget(Experiment):
    def _get_treatments(self):
        if len(self.eps) &gt; 0:
            print(&#34;[WARN] Using first value of epsilon for budget calcs.&#34;)

        e = self.eps[0]
        alpha = 0.05
        test = self.baseline.loc[pd.IndexSlice[:, 0.0, e, :, :], :]

        budgets = {
            &#34;Biden proposal&#34;: 2e10
        }
        for name, prefixes in {
            &#34;+ loss&#34;: (&#34;dpest&#34;, &#34;true&#34;),
            # &#34;+ marginal loss (DP)&#34;: (&#34;dpest&#34;, &#34;est&#34;),
            # &#34;+ loss (data error)&#34;: (&#34;est&#34;, &#34;true&#34;)
        }.items():
            error = test[f&#34;{prefixes[1]}_grant_total&#34;] \
                - test[f&#34;{prefixes[0]}_grant_total&#34;]
            err_grouped = error.groupby(
                [&#34;State FIPS Code&#34;, &#34;District ID&#34;]
            )
            exp_error = err_grouped.mean()

            budgets[name] = exp_error[exp_error &lt; 0].abs().sum()

            if prefixes == (&#34;dpest&#34;, &#34;true&#34;):
                # how much money to remove alpha quantile loss?
                quantile = err_grouped.quantile(alpha)
                budgets[f&#34;+ {(alpha)*100}% quant. loss&#34;] = \
                    quantile[quantile &lt; 0].abs().sum()

                # how much money to cover all misallocated dollars?
                # budgets[f&#34;+ exp. misalloc.&#34;] = exp_error.abs().sum()

        budgets = {&#34;{} (${:.1e})&#34;.format(k, v): v for k, v in budgets.items()}

        usual_budget = self.saipe[&#34;official_total_alloc&#34;]\
            .groupby([&#34;State FIPS Code&#34;, &#34;District ID&#34;]).first().sum()
        print(&#34;baseline budget: {:.1e}&#34;.format(usual_budget))
        print(budgets)

        treatments = {
            name: titlei_grid(
                self.saipe, Laplace,
                eps=[e], delta=self.delta,
                trials=self.trials, print_results=False,
                allocator_kwargs={
                    &#39;appropriation&#39;: round(budget + usual_budget, 2)
                }
            ) for name, budget in budgets.items()
        }
        match_true(self.baseline, list(treatments.values()))
        treatments[&#34;FY2019 appropriation (baseline)&#34;] = test

        return treatments</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></li>
</ul>
</dd>
<dt id="dp_policy.experiments.Epsilon"><code class="flex name class">
<span>class <span class="ident">Epsilon</span></span>
<span>(</span><span>name, baseline='cached', year=2021, trials=1000, eps=[0.1], delta=[0.0])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L561-L577" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Epsilon(Experiment):
    def _get_treatments(self):
        return {
            e: titlei_grid(
                self.saipe, Laplace,
                eps=[e], delta=self.delta,
                trials=self.trials, print_results=False
            ) if e not in self.eps
            else self.baseline.loc[pd.IndexSlice[:, 0.0, e, :, :], :].copy()
            for e in [1e-3, 1e-2, 1e-1, 1, 10, 30]
        }

    def discrimination_join(self):
        return super().discrimination_join(epsilon=None)

    def plot(self):
        return super().plot(epsilon=None)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="dp_policy.experiments.Epsilon.discrimination_join"><code class="name flex">
<span>def <span class="ident">discrimination_join</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L573-L574" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def discrimination_join(self):
    return super().discrimination_join(epsilon=None)</code></pre>
</details>
</dd>
<dt id="dp_policy.experiments.Epsilon.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L576-L577" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def plot(self):
    return super().plot(epsilon=None)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dp_policy.experiments.Experiment"><code class="flex name class">
<span>class <span class="ident">Experiment</span></span>
<span>(</span><span>name, baseline='cached', year=2021, trials=1000, eps=[0.1], delta=[0.0])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L244-L315" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Experiment:
    def __init__(
        self,
        name,
        baseline=&#34;cached&#34;,
        year=2021,
        trials=1000,
        eps=[0.1],
        delta=[0.0]
    ):
        self.name = name
        self.trials = trials
        self.eps = eps
        self.delta = delta
        self.saipe = get_inputs(year)

        if str(baseline) == &#34;cached&#34;:
            print(&#34;Using cached baseline...&#34;)
            try:
                self.baseline = load_treatments(&#34;baseline&#34;)[&#39;baseline&#39;]
            except FileNotFoundError:
                print(&#34;[WARN] Could not find cached baseline, generating.&#34;)
                self._generate_baseline()
        elif baseline is None:
            print(&#34;Generating baseline...&#34;)
            self._generate_baseline()
        else:
            print(&#34;Using given baseline...&#34;)
            self.baseline = baseline

    def _generate_baseline(self):
        self.baseline = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps, delta=self.delta,
            trials=self.trials,
            print_results=False,
            allocator_kwargs={&#39;verbose&#39;: False}
        )
        save_treatments({&#39;baseline&#39;: self.baseline}, &#34;baseline&#34;)
        discrimination_treatments_join(&#34;baseline&#34;)

    def run(self):
        treatments = self._get_treatments()
        save_treatments(treatments, self.name)
        self.discrimination_join()

    def _get_treatments(self):
        raise NotImplementedError

    def discrimination_join(self, **join_kwargs):
        discrimination_treatments_join(self.name, **join_kwargs)

    def plot(self, **kwargs):
        treatments = load_treatments(self.name)
        compare_treatments(treatments, experiment_name=self.name, **kwargs)

    @staticmethod
    def get_experiment(name, *args, **kwargs):
        experiments = {
            &#39;baseline&#39;: Baseline,
            &#39;hold_harmless&#39;: HoldHarmless,
            &#39;post_processing&#39;: PostProcessing,
            &#39;thresholds&#39;: Thresholds,
            &#39;epsilon&#39;: Epsilon,
            &#39;moving_average&#39;: MovingAverage,
            &#39;budget&#39;: Budget,
            &#39;sampling&#39;: Sampling
        }
        Exp = experiments.get(name)
        if Exp is None:
            raise ValueError(f&#34;{name} not a supported experiment name.&#34;)
        return Exp(name, *args, **kwargs)</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Baseline" href="#dp_policy.experiments.Baseline">Baseline</a></li>
<li><a title="dp_policy.experiments.Budget" href="#dp_policy.experiments.Budget">Budget</a></li>
<li><a title="dp_policy.experiments.Epsilon" href="#dp_policy.experiments.Epsilon">Epsilon</a></li>
<li><a title="dp_policy.experiments.HoldHarmless" href="#dp_policy.experiments.HoldHarmless">HoldHarmless</a></li>
<li><a title="dp_policy.experiments.MovingAverage" href="#dp_policy.experiments.MovingAverage">MovingAverage</a></li>
<li><a title="dp_policy.experiments.PostProcessing" href="#dp_policy.experiments.PostProcessing">PostProcessing</a></li>
<li><a title="dp_policy.experiments.Sampling" href="#dp_policy.experiments.Sampling">Sampling</a></li>
<li><a title="dp_policy.experiments.Thresholds" href="#dp_policy.experiments.Thresholds">Thresholds</a></li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="dp_policy.experiments.Experiment.get_experiment"><code class="name flex">
<span>def <span class="ident">get_experiment</span></span>(<span>name, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L300-L315" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@staticmethod
def get_experiment(name, *args, **kwargs):
    experiments = {
        &#39;baseline&#39;: Baseline,
        &#39;hold_harmless&#39;: HoldHarmless,
        &#39;post_processing&#39;: PostProcessing,
        &#39;thresholds&#39;: Thresholds,
        &#39;epsilon&#39;: Epsilon,
        &#39;moving_average&#39;: MovingAverage,
        &#39;budget&#39;: Budget,
        &#39;sampling&#39;: Sampling
    }
    Exp = experiments.get(name)
    if Exp is None:
        raise ValueError(f&#34;{name} not a supported experiment name.&#34;)
    return Exp(name, *args, **kwargs)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dp_policy.experiments.Experiment.discrimination_join"><code class="name flex">
<span>def <span class="ident">discrimination_join</span></span>(<span>self, **join_kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L293-L294" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def discrimination_join(self, **join_kwargs):
    discrimination_treatments_join(self.name, **join_kwargs)</code></pre>
</details>
</dd>
<dt id="dp_policy.experiments.Experiment.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L296-L298" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def plot(self, **kwargs):
    treatments = load_treatments(self.name)
    compare_treatments(treatments, experiment_name=self.name, **kwargs)</code></pre>
</details>
</dd>
<dt id="dp_policy.experiments.Experiment.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L285-L288" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def run(self):
    treatments = self._get_treatments()
    save_treatments(treatments, self.name)
    self.discrimination_join()</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dp_policy.experiments.HoldHarmless"><code class="flex name class">
<span>class <span class="ident">HoldHarmless</span></span>
<span>(</span><span>name, baseline='cached', year=2021, trials=1000, eps=[0.1], delta=[0.0])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L325-L357" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class HoldHarmless(Experiment):
    def _get_treatments(self):
        hold_harmless = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps, delta=self.delta,
            trials=self.trials, print_results=False,
            allocator_kwargs={&#39;hold_harmless&#39;: True}
        )
        state_minimum = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps, delta=self.delta,
            trials=self.trials, print_results=False,
            allocator_kwargs={&#39;state_minimum&#39;: True}
        )
        both = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps, delta=self.delta,
            trials=self.trials, print_results=False,
            allocator_kwargs={
                &#39;hold_harmless&#39;: True,
                &#39;state_minimum&#39;: True
            }
        )
        # ground truths are the same
        match_true(self.baseline, [hold_harmless, state_minimum, both])

        # save treatments to file for later
        return {
            &#39;No provisions (baseline)&#39;: self.baseline,
            &#39;Hold harmless only&#39;: hold_harmless,
            &#39;State minimum only&#39;: state_minimum,
            &#39;Both provisions&#39;: both
        }</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></li>
</ul>
</dd>
<dt id="dp_policy.experiments.MovingAverage"><code class="flex name class">
<span>class <span class="ident">MovingAverage</span></span>
<span>(</span><span>name, truth='average', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L393-L419" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class MovingAverage(Experiment):
    def __init__(self, name, truth=&#34;average&#34;, **kwargs):
        if truth != &#34;average&#34;:
            raise Exception(
                &#34;Not supporting truth values other than `average`.&#34;
            )
        self.truth = truth
        super().__init__(f&#34;{name}_truth={truth}&#34;, **kwargs)

    def _get_treatments(self):
        single_year = self.baseline
        averaged = [
            titlei_grid(
                get_inputs(2021, avg_lag=i+1),
                Laplace,
                eps=self.eps,
                delta=self.delta,
                trials=self.trials,
                print_results=False
            )
            for i in range(4)
        ]
        match_true(averaged[-1], [single_year] + averaged[:-1])
        return {
            &#39;Lag 0&#39;: single_year,
            **{f&#34;Lag {i+1}&#34;: a for i, a in enumerate(averaged)}
        }</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></li>
</ul>
</dd>
<dt id="dp_policy.experiments.PostProcessing"><code class="flex name class">
<span>class <span class="ident">PostProcessing</span></span>
<span>(</span><span>name, baseline='cached', year=2021, trials=1000, eps=[0.1], delta=[0.0])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L360-L390" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class PostProcessing(Experiment):
    def _get_treatments(self):
        none = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            mech_kwargs=dict(
                clip=False,
                round=False
            ),
            print_results=False
        )
        clipping = self.baseline
        rounding = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            mech_kwargs=dict(
                clip=True,
                round=True
            ),
            print_results=False
        )
        match_true(self.baseline, [none, rounding])
        return {
            &#39;None&#39;: none,
            &#39;Clipping (baseline)&#39;: clipping,
            &#39;Clipping + Rounding&#39;: rounding
        }</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></li>
</ul>
</dd>
<dt id="dp_policy.experiments.Sampling"><code class="flex name class">
<span>class <span class="ident">Sampling</span></span>
<span>(</span><span>name, baseline='cached', year=2021, trials=1000, eps=[0.1], delta=[0.0])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L580-L609" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Sampling(Experiment):
    def _get_treatments(self):
        gaussian = {
            f&#34;Gaussian ({m})&#34;: titlei_grid(
                self.saipe, Laplace,
                eps=self.eps, delta=self.delta,
                trials=self.trials, print_results=False,
                sampling_kwargs=dict(
                    multiplier=m,
                    distribution=&#34;gaussian&#34;
                )
            )
            for m in [0.5, 0.75, 1, 1.5]
        }
        laplace = {
            f&#34;Laplace ({m})&#34;: titlei_grid(
                self.saipe, Laplace,
                eps=self.eps, delta=self.delta,
                trials=self.trials, print_results=False,
                sampling_kwargs=dict(
                    multiplier=m,
                    distribution=&#34;laplace&#34;
                )
            )
            for m in [0.5, 1, 1.5]
        }
        return {
            **gaussian,
            **laplace
        }</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></li>
</ul>
</dd>
<dt id="dp_policy.experiments.Thresholds"><code class="flex name class">
<span>class <span class="ident">Thresholds</span></span>
<span>(</span><span>name, baseline='cached', year=2021, trials=1000, eps=[0.1], delta=[0.0])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/1516db333ae8cc10611522f527ea8b41022f109a/dp_policy/experiments.py#L422-L500" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Thresholds(Experiment):
    def _get_treatments(self):
        # hard threshold
        hard = self.baseline

        # use average
        averaged = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: AverageThresholder(2021, 4)
            },
            print_results=False
        )

        # must be ineligible 2x in a row
        repeat2 = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: RepeatThresholder(2021, 1)
            },
            print_results=False
        )

        # must be ineligible 3x in a row
        repeat3 = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: RepeatThresholder(2021, 2)
            },
            print_results=False
        )

        # no threshold
        none = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: DummyThresholder()
            },
            print_results=False
        )

        # moe
        moe_01 = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: MOEThresholder(alpha=0.1)
            },
            print_results=False
        )

        match_true(hard, [averaged, repeat2, repeat3, none, moe_01])
        return {
            &#39;None&#39;: none,
            &#39;Hard (baseline)&#39;: hard,
            &#39;Averaged&#39;: averaged,
            &#39;Repeated years (2)&#39;: repeat2,
            &#39;Repeated years (3)&#39;: repeat3,
            &#39;Margin of error (90%)&#39;: moe_01
        }</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dp_policy" href="index.html">dp_policy</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="dp_policy.experiments.titlei_funding" href="#dp_policy.experiments.titlei_funding">titlei_funding</a></code></li>
<li><code><a title="dp_policy.experiments.titlei_grid" href="#dp_policy.experiments.titlei_grid">titlei_grid</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dp_policy.experiments.Baseline" href="#dp_policy.experiments.Baseline">Baseline</a></code></h4>
</li>
<li>
<h4><code><a title="dp_policy.experiments.Budget" href="#dp_policy.experiments.Budget">Budget</a></code></h4>
</li>
<li>
<h4><code><a title="dp_policy.experiments.Epsilon" href="#dp_policy.experiments.Epsilon">Epsilon</a></code></h4>
<ul class="">
<li><code><a title="dp_policy.experiments.Epsilon.discrimination_join" href="#dp_policy.experiments.Epsilon.discrimination_join">discrimination_join</a></code></li>
<li><code><a title="dp_policy.experiments.Epsilon.plot" href="#dp_policy.experiments.Epsilon.plot">plot</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></code></h4>
<ul class="">
<li><code><a title="dp_policy.experiments.Experiment.discrimination_join" href="#dp_policy.experiments.Experiment.discrimination_join">discrimination_join</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.get_experiment" href="#dp_policy.experiments.Experiment.get_experiment">get_experiment</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.plot" href="#dp_policy.experiments.Experiment.plot">plot</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.run" href="#dp_policy.experiments.Experiment.run">run</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dp_policy.experiments.HoldHarmless" href="#dp_policy.experiments.HoldHarmless">HoldHarmless</a></code></h4>
</li>
<li>
<h4><code><a title="dp_policy.experiments.MovingAverage" href="#dp_policy.experiments.MovingAverage">MovingAverage</a></code></h4>
</li>
<li>
<h4><code><a title="dp_policy.experiments.PostProcessing" href="#dp_policy.experiments.PostProcessing">PostProcessing</a></code></h4>
</li>
<li>
<h4><code><a title="dp_policy.experiments.Sampling" href="#dp_policy.experiments.Sampling">Sampling</a></code></h4>
</li>
<li>
<h4><code><a title="dp_policy.experiments.Thresholds" href="#dp_policy.experiments.Thresholds">Thresholds</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>