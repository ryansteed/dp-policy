<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>dp_policy.experiments API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dp_policy.experiments</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/0a16f5ad99bbed9ce1f570f085a3e6b58a56bdca/dp_policy/experiments.py#L1-L682" class="git-link">Browse git</a>
</summary>
<pre><code class="python">import os
import pandas as pd
from tqdm import tqdm
import numpy as np
import itertools
import matplotlib.pyplot as plt

import dp_policy.config as config
from dp_policy.titlei.evaluation import \
    discrimination_treatments_join, save_treatments, load_treatments, \
    match_true, compare_treatments, misalloc_statistics
from dp_policy.titlei.mechanisms import Mechanism, Laplace
from dp_policy.titlei.utils import get_inputs, data, get_sppe
from dp_policy.titlei.allocators import Allocator, SonnenbergAuthorizer
from dp_policy.titlei.thresholders import \
    AverageThresholder, RepeatThresholder, DummyThresholder, MOEThresholder, \
    PastThresholder

from typing import List, Union


def titlei_funding(
    allocator: Allocator,
    inputs: pd.DataFrame,
    mechanism: Mechanism,
    sppe: pd.DataFrame,
    normalize: bool = True,
    allocator_kwargs: dict = {},
    sampling_kwargs: dict = {},
    **grants_kwargs
):
    &#34;&#34;&#34;Allocate Title I funding.

    Args:
        allocator (Allocator): The allocator to use.
        inputs (pd.DataFrame): The necessary inputs for the allocator -
            usually the SAIPE - by district.
        mechanism (Mechanism): The randomization mechanism to use.
        sppe (pd.DataFrame): State per-pupil education data.
        normalize (bool, optional): Whether to normalize the authorization
            amounts. Defaults to True.
        allocator_kwargs (dict, optional): Parameters for the allocator.
            Defaults to {}.
        sampling_kwargs (dict, optional): Parameters for the sampling
            mechanism. Defaults to {}.

    Returns:
        pd.DataFrame: Returns input dataframe with grant allocations under
            ground truth, sampling, and privacy randomization.
    &#34;&#34;&#34;
    alloc = allocator(
        data(
            inputs, mechanism, sppe,
            sampling_kwargs=sampling_kwargs,
            **grants_kwargs
        ),
        **allocator_kwargs
    )
    return alloc.allocations(normalize=normalize)


def titlei_grid(
    inputs: pd.DataFrame,
    mech: Mechanism,
    eps: list = list(np.logspace(-3, 10, num=10)) + [2.52],
    delta: list = [0.0],
    trials: int = 100,
    mech_kwargs: dict = {},
    auth: bool = False,
    allocator_kwargs: dict = {},
    sampling_kwargs: dict = {},
    verbose: bool = True,
    print_results: list = [2.52, 0.1],
    plot_results: bool = False,
    alpha: float = 0.05,
    results: pd.DataFrame = None
):
    &#34;&#34;&#34;Run many trials of Title I process under different privacy parameters.

    Args:
        inputs (pd.DataFrame): The necessary inputs for the allocator -
            usually the SAIPE - by district.
        mech (Mechanism): The randomization mechanism to use.
        eps (list, optional): Values of epsilon to try. Defaults to
            `list(np.logspace(-3, 10, num=10))+[2.52]`.
        delta (list, optional): Values of delta to try. Defaults to [0.0].
        trials (int, optional): Number of trials to run for each parameter
            combo. Defaults to 100.
        mech_kwargs (dict, optional): Parameters for the randomization
            mechanism. Defaults to {}.
        auth (bool, optional): Whether to use the raw authorization amounts.
            Defaults to False.
        allocator_kwargs (dict, optional): Parameters for the allocator.
            Defaults to {}.
        sampling_kwargs (dict, optional): Parameters for the sampling
            mechanism. Defaults to {}.
        verbose (bool, optional): Defaults to True.
        print_results (list, optional): Which values of epsilon to print
            results for. Defaults to [2.52, 0.1].
        plot_results (bool, optional): Whether to plot results. Defaults to
            False.
        alpha (float, optional): Confidence level for confidence bands.
            Defaults to 0.05.
        results (pd.DataFrame, optional): Pre-computed results to plot. If
            provided, will skip grid calculation. Defaults to None.

    Returns:
        pd.DataFrame: Results grid.
    &#34;&#34;&#34;
    if results is None:
        allocations = []
        thresholder = allocator_kwargs.get(&#39;thresholder&#39;)
        if verbose:
            print(f&#34;{len(eps)*len(delta)*trials} iters:&#34;)
        for trial in tqdm(range(trials), desc=&#39;trial&#39;, disable=(not verbose)):
            for d in tqdm(delta, desc=&#39;delta&#39;, leave=False, disable=True):
                for e in tqdm(eps, desc=&#39;eps&#39;, leave=False, disable=True):
                    mechanism = mech(e, d, **mech_kwargs)
                    sppe = get_sppe(os.path.join(
                        config.root,
                        &#34;data/sppe18.xlsx&#34;
                    ))
                    if thresholder is not None and isinstance(
                            thresholder, PastThresholder
                    ):
                        thresholder.set_prior_estimates(
                            mechanism,
                            sppe,
                            verbose=False
                        )
                    allocations.append(titlei_funding(
                        SonnenbergAuthorizer,
                        inputs,
                        mechanism,
                        sppe,
                        allocator_kwargs=allocator_kwargs,
                        sampling_kwargs=sampling_kwargs,
                        verbose=False,  # too noisy for a grid search
                        normalize=(not auth)
                    ))
        results = pd.concat(
            allocations, axis=0,
            keys=itertools.product(range(trials), delta, eps),
            names=[
                &#34;trial&#34;, &#34;delta&#34;, &#34;epsilon&#34;
            ] + list(allocations[-1].index.names)
        )

    if print_results:
        prefixes = [&#34;est&#34;, &#34;dp&#34;, &#34;dpest&#34;]

        for e, alloc in results.groupby(&#34;epsilon&#34;):
            if e in print_results:
                print(f&#34;--- eps={e} ---&#34;)
                data_error = alloc[&#34;est_children_eligible&#34;] \
                    - alloc[&#34;true_children_eligible&#34;]
                dp_error = alloc[&#34;dpest_children_eligible&#34;] \
                    - alloc[&#34;est_children_eligible&#34;]
                s = 0.5
                plt.scatter(
                    alloc[&#34;true_children_eligible&#34;], data_error,
                    s, label=&#34;data&#34;
                )
                plt.scatter(
                    alloc[&#34;true_children_eligible&#34;], dp_error,
                    s, label=&#34;dp&#34;
                )
                plt.legend()
                plt.xlabel(&#34;# children in poverty&#34;)
                plt.ylabel(&#34;Noise&#34;)
                plt.show()

                plt.scatter(
                    alloc[&#34;true_children_eligible&#34;],
                    data_error/alloc[&#34;true_children_eligible&#34;],
                    s, label=&#34;data&#34;
                )
                plt.scatter(
                    alloc[&#34;true_children_eligible&#34;],
                    dp_error/alloc[&#34;true_children_eligible&#34;],
                    s, label=&#34;dp&#34;
                )
                plt.legend()
                plt.xlabel(&#34;# children in poverty&#34;)
                plt.ylabel(&#34;Noise per child in poverty&#34;)
                plt.show()

        for prefix in prefixes:
            print(&#34;##&#34;, prefix)
            for e, alloc in results.groupby(&#34;epsilon&#34;):
                for grant_type in (
                    &#34;basic&#34;, &#34;concentration&#34;, &#34;targeted&#34;, &#34;total&#34;
                ):
                    if e in print_results:
                        error = alloc[f&#34;{prefix}_grant_{grant_type}&#34;] \
                            - alloc[f&#34;true_grant_{grant_type}&#34;]
                        print(f&#34;## {grant_type} grants - eps={e} ##&#34;)
                        misalloc_statistics(
                            error,
                            allocations=alloc,
                            grant_type=grant_type
                        )

            if plot_results:
                trials = len(np.unique(
                    results.index.get_level_values(&#34;trial&#34;)
                ))

                grant_type = &#34;total&#34;

                error = results[f&#34;{prefix}_grant_{grant_type}&#34;] \
                    - results[f&#34;true_grant_{grant_type}&#34;]
                print(error.shape)
                rmse = np.sqrt(error.pow(2).groupby(
                    [&#34;epsilon&#34;, &#34;trial&#34;]
                ).mean())
                print(rmse)
                mse = {
                    &#39;mean&#39;: rmse.groupby(&#34;epsilon&#34;).mean(),
                    &#39;lower&#39;: rmse.groupby(&#34;epsilon&#34;).quantile(alpha/2),
                    &#39;upper&#39;: rmse.groupby(&#34;epsilon&#34;).quantile(1-alpha/2)
                }
                eps = mse[&#39;mean&#39;].index
                plt.plot(eps, mse[&#39;mean&#39;])
                plt.fill_between(
                    eps, mse[&#39;lower&#39;], mse[&#39;upper&#39;],
                    color=&#39;gray&#39;, alpha=0.25
                )
                ax = plt.gca()
                ax.set_xscale(&#39;log&#39;)
                plt.xlabel(&#34;Epsilon&#34;)
                plt.ylabel(
                    f&#34;Avg. RMSE in {grant_type} grants over {trials} trials&#34;
                )
                plt.savefig(
                    os.path.join(
                        config.root,
                        &#34;plots/robustness/eps_sensitivity_frontier.png&#34;
                    ),
                    dpi=300
                )
                plt.show()

    return results


class Experiment:
    &#34;&#34;&#34;Handles running and setting experiments.
    &#34;&#34;&#34;
    def __init__(
        self,
        name: str,
        baseline: Union[str, pd.DataFrame] = &#34;cached&#34;,
        year: int = 2021,
        trials: int = 1000,
        eps: List[float] = [0.1],
        delta: List[float] = [0.0]
    ):
        &#34;&#34;&#34;Initialize experiment and set baseline.

        Args:
            name (str): Experiment name.
            baseline (Union[str, pd.DataFrame], optional): What baseline
                (control) results to use. Defaults to &#34;cached&#34;.
            year (int, optional): What year to get inputs for. Defaults to
                2021.
            trials (int, optional): Number of trials to run for each condition.
                Defaults to 1000.
            eps (List[float], optional): Values of epsilon to try. Defaults to
                [0.1].
            delta (List[float], optional): Values of delta to try. Defaults to
                [0.0].
        &#34;&#34;&#34;
        self.name = name
        self.trials = trials
        self.eps = eps
        self.delta = delta
        self.saipe = get_inputs(year)

        if str(baseline) == &#34;cached&#34;:
            print(&#34;Using cached baseline...&#34;)
            try:
                self.baseline = load_treatments(&#34;baseline&#34;)[&#39;baseline&#39;]
            except FileNotFoundError:
                print(&#34;[WARN] Could not find cached baseline, generating.&#34;)
                self._generate_baseline()
        elif baseline is None:
            print(&#34;Generating baseline...&#34;)
            self._generate_baseline()
        else:
            print(&#34;Using given baseline...&#34;)
            self.baseline = baseline

    def _generate_baseline(self):
        &#34;&#34;&#34;Generate the control condition. Defaults to normal Laplace
            mechanism with no special allocation parameters.
        &#34;&#34;&#34;
        self.baseline = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps, delta=self.delta,
            trials=self.trials,
            print_results=False,
            allocator_kwargs={&#39;verbose&#39;: False}
        )
        save_treatments({&#39;baseline&#39;: self.baseline}, &#34;baseline&#34;)
        discrimination_treatments_join(&#34;baseline&#34;)

    def run(self):
        &#34;&#34;&#34;Run the experiment, save results, and create joined covariate file.
        &#34;&#34;&#34;
        treatments = self._get_treatments()
        save_treatments(treatments, self.name)
        self.discrimination_join()

    def _get_treatments(self):
        &#34;&#34;&#34;Generate the treatment results.
        &#34;&#34;&#34;
        raise NotImplementedError

    def discrimination_join(self, **join_kwargs):
        &#34;&#34;&#34;Join the results to demographic covariates and save.
        &#34;&#34;&#34;
        discrimination_treatments_join(self.name, **join_kwargs)

    def plot(self, **kwargs):
        &#34;&#34;&#34;Print and plot the results, comparing treatments.
        &#34;&#34;&#34;
        treatments = load_treatments(self.name)
        compare_treatments(treatments, experiment_name=self.name, **kwargs)

    @staticmethod
    def get_experiment(
        name: str,
        *args, **kwargs
    ):
        &#34;&#34;&#34;Factory class for generating experiment object from name.

        Args:
            name (str): Experiment name to fetch. Options include &#34;baseline&#34;,
                &#34;hold_harmless&#34;, &#34;post_processing&#34;, &#34;thresholds&#34;, &#34;epsilon&#34;,
                &#34;moving_average&#34;, &#34;budget&#34;, &#34;sampling&#34;.

        Returns:
            Experiment: The experiment object.
        &#34;&#34;&#34;
        experiments = {
            &#39;baseline&#39;: Baseline,
            &#39;hold_harmless&#39;: HoldHarmless,
            &#39;post_processing&#39;: PostProcessing,
            &#39;thresholds&#39;: Thresholds,
            &#39;epsilon&#39;: Epsilon,
            &#39;moving_average&#39;: MovingAverage,
            &#39;budget&#39;: Budget,
            &#39;sampling&#39;: Sampling
        }
        Exp = experiments.get(name)
        if Exp is None:
            raise ValueError(f&#34;{name} not a supported experiment name.&#34;)
        return Exp(name, *args, **kwargs)


class Baseline(Experiment):
    &#34;&#34;&#34;Baseline condition only.
    &#34;&#34;&#34;
    def _get_treatments(self):
        return {
            &#39;baseline&#39;: self.baseline
        }


class HoldHarmless(Experiment):
    &#34;&#34;&#34;Hold harmless and state minimum provisions.
    &#34;&#34;&#34;
    def _get_treatments(self):
        hold_harmless = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps, delta=self.delta,
            trials=self.trials, print_results=False,
            allocator_kwargs={&#39;hold_harmless&#39;: True}
        )
        state_minimum = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps, delta=self.delta,
            trials=self.trials, print_results=False,
            allocator_kwargs={&#39;state_minimum&#39;: True}
        )
        both = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps, delta=self.delta,
            trials=self.trials, print_results=False,
            allocator_kwargs={
                &#39;hold_harmless&#39;: True,
                &#39;state_minimum&#39;: True
            }
        )
        # ground truths are the same
        match_true(self.baseline, [hold_harmless, state_minimum, both])

        # save treatments to file for later
        return {
            &#39;No provisions (baseline)&#39;: self.baseline,
            &#39;Hold harmless only&#39;: hold_harmless,
            &#39;State minimum only&#39;: state_minimum,
            &#39;Both provisions&#39;: both
        }


class PostProcessing(Experiment):
    &#34;&#34;&#34;Post-processing variations: none, clipping, and clipping + rounding.
    &#34;&#34;&#34;
    def _get_treatments(self):
        none = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            mech_kwargs=dict(
                clip=False,
                round=False
            ),
            print_results=False
        )
        clipping = self.baseline
        rounding = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            mech_kwargs=dict(
                clip=True,
                round=True
            ),
            print_results=False
        )
        match_true(self.baseline, [none, rounding])
        return {
            &#39;None&#39;: none,
            &#39;Clipping (baseline)&#39;: clipping,
            &#39;Clipping + Rounding&#39;: rounding
        }


class MovingAverage(Experiment):
    &#34;&#34;&#34;Moving average inputs, with multiple lag conditions.
    &#34;&#34;&#34;
    def __init__(
        self,
        name: str,
        truth: str = &#34;average&#34;,
        **kwargs
    ):
        &#34;&#34;&#34;
        Args:
            truth (str, optional): Baseline strategy to use. &#34;average&#34; uses
                the 5-year average as the baseline. Defaults to &#34;average&#34;.

        Raises:
            Exception: _description_
        &#34;&#34;&#34;
        if truth != &#34;average&#34;:
            raise Exception(
                &#34;Not supporting truth values other than `average`.&#34;
            )
        self.truth = truth
        super().__init__(f&#34;{name}_truth={truth}&#34;, **kwargs)

    def _get_treatments(self):
        single_year = self.baseline
        averaged = [
            titlei_grid(
                get_inputs(2021, avg_lag=i+1),
                Laplace,
                eps=self.eps,
                delta=self.delta,
                trials=self.trials,
                print_results=False
            )
            for i in range(4)
        ]
        match_true(averaged[-1], [single_year] + averaged[:-1])
        return {
            &#39;Lag 0&#39;: single_year,
            **{f&#34;Lag {i+1}&#34;: a for i, a in enumerate(averaged)}
        }


class Thresholds(Experiment):
    &#34;&#34;&#34;Thresholding experiments.
    &#34;&#34;&#34;
    def _get_treatments(self):
        # hard threshold
        hard = self.baseline

        # use average
        averaged = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: AverageThresholder(2021, 4)
            },
            print_results=False
        )

        # must be ineligible 2x in a row
        repeat2 = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: RepeatThresholder(2021, 1)
            },
            print_results=False
        )

        # must be ineligible 3x in a row
        repeat3 = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: RepeatThresholder(2021, 2)
            },
            print_results=False
        )

        # no threshold
        none = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: DummyThresholder()
            },
            print_results=False
        )

        # moe
        moe_01 = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: MOEThresholder(alpha=0.1)
            },
            print_results=False
        )

        match_true(hard, [averaged, repeat2, repeat3, none, moe_01])
        return {
            &#39;None&#39;: none,
            &#39;Hard (baseline)&#39;: hard,
            &#39;Averaged&#39;: averaged,
            &#39;Repeated years (2)&#39;: repeat2,
            &#39;Repeated years (3)&#39;: repeat3,
            &#39;Margin of error (90%)&#39;: moe_01
        }


class Budget(Experiment):
    &#34;&#34;&#34;Budget experiments.
    &#34;&#34;&#34;
    def _get_treatments(self):
        if len(self.eps) &gt; 0:
            print(&#34;[WARN] Using first value of epsilon for budget calcs.&#34;)

        e = self.eps[0]
        alpha = 0.05
        test = self.baseline.loc[pd.IndexSlice[:, 0.0, e, :, :], :]

        budgets = {
            &#34;Biden proposal&#34;: 2e10
        }
        for name, prefixes in {
            &#34;+ loss&#34;: (&#34;dpest&#34;, &#34;true&#34;),
            # &#34;+ marginal loss (DP)&#34;: (&#34;dpest&#34;, &#34;est&#34;),
            # &#34;+ loss (data error)&#34;: (&#34;est&#34;, &#34;true&#34;)
        }.items():
            error = test[f&#34;{prefixes[1]}_grant_total&#34;] \
                - test[f&#34;{prefixes[0]}_grant_total&#34;]
            err_grouped = error.groupby(
                [&#34;State FIPS Code&#34;, &#34;District ID&#34;]
            )
            exp_error = err_grouped.mean()

            budgets[name] = exp_error[exp_error &lt; 0].abs().sum()

            if prefixes == (&#34;dpest&#34;, &#34;true&#34;):
                # how much money to remove alpha quantile loss?
                quantile = err_grouped.quantile(alpha)
                budgets[f&#34;+ {(alpha)*100}% quant. loss&#34;] = \
                    quantile[quantile &lt; 0].abs().sum()

                # how much money to cover all misallocated dollars?
                # budgets[f&#34;+ exp. misalloc.&#34;] = exp_error.abs().sum()

        budgets = {&#34;{} (${:.1e})&#34;.format(k, v): v for k, v in budgets.items()}

        usual_budget = self.saipe[&#34;official_total_alloc&#34;]\
            .groupby([&#34;State FIPS Code&#34;, &#34;District ID&#34;]).first().sum()
        print(&#34;baseline budget: {:.1e}&#34;.format(usual_budget))
        print(budgets)

        treatments = {
            name: titlei_grid(
                self.saipe, Laplace,
                eps=[e], delta=self.delta,
                trials=self.trials, print_results=False,
                allocator_kwargs={
                    &#39;appropriation&#39;: round(budget + usual_budget, 2)
                }
            ) for name, budget in budgets.items()
        }
        match_true(self.baseline, list(treatments.values()))
        treatments[&#34;FY2019 appropriation (baseline)&#34;] = test

        return treatments


class Epsilon(Experiment):
    &#34;&#34;&#34;Privacy parameter experiments.
    &#34;&#34;&#34;
    def _get_treatments(self):
        return {
            e: titlei_grid(
                self.saipe, Laplace,
                eps=[e], delta=self.delta,
                trials=self.trials, print_results=False
            ) if e not in self.eps
            else self.baseline.loc[pd.IndexSlice[:, 0.0, e, :, :], :].copy()
            for e in [1e-3, 1e-2, 1e-1, 1, 10, 30]
        }

    def discrimination_join(self):
        return super().discrimination_join(epsilon=None)

    def plot(self):
        return super().plot(epsilon=None)


class Sampling(Experiment):
    &#34;&#34;&#34;Sampling error experiments.
    &#34;&#34;&#34;
    def _get_treatments(self):
        gaussian = {
            f&#34;Gaussian ({m})&#34;: titlei_grid(
                self.saipe, Laplace,
                eps=self.eps, delta=self.delta,
                trials=self.trials, print_results=False,
                sampling_kwargs=dict(
                    multiplier=m,
                    distribution=&#34;gaussian&#34;
                )
            )
            for m in [0.5, 0.75, 1, 1.5]
        }
        laplace = {
            f&#34;Laplace ({m})&#34;: titlei_grid(
                self.saipe, Laplace,
                eps=self.eps, delta=self.delta,
                trials=self.trials, print_results=False,
                sampling_kwargs=dict(
                    multiplier=m,
                    distribution=&#34;laplace&#34;
                )
            )
            for m in [0.5, 1, 1.5]
        }
        return {
            **gaussian,
            **laplace
        }</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dp_policy.experiments.titlei_funding"><code class="name flex">
<span>def <span class="ident">titlei_funding</span></span>(<span>allocator: <a title="dp_policy.titlei.allocators.Allocator" href="titlei/allocators.html#dp_policy.titlei.allocators.Allocator">Allocator</a>, inputs: pandas.core.frame.DataFrame, mechanism: <a title="dp_policy.titlei.mechanisms.Mechanism" href="titlei/mechanisms.html#dp_policy.titlei.mechanisms.Mechanism">Mechanism</a>, sppe: pandas.core.frame.DataFrame, normalize: bool = True, allocator_kwargs: dict = {}, sampling_kwargs: dict = {}, **grants_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Allocate Title I funding.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>allocator</code></strong> :&ensp;<code>Allocator</code></dt>
<dd>The allocator to use.</dd>
<dt><strong><code>inputs</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>The necessary inputs for the allocator -
usually the SAIPE - by district.</dd>
<dt><strong><code>mechanism</code></strong> :&ensp;<code>Mechanism</code></dt>
<dd>The randomization mechanism to use.</dd>
<dt><strong><code>sppe</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>State per-pupil education data.</dd>
<dt><strong><code>normalize</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to normalize the authorization
amounts. Defaults to True.</dd>
<dt><strong><code>allocator_kwargs</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Parameters for the allocator.
Defaults to {}.</dd>
<dt><strong><code>sampling_kwargs</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Parameters for the sampling
mechanism. Defaults to {}.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>Returns input dataframe with grant allocations under
ground truth, sampling, and privacy randomization.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/0a16f5ad99bbed9ce1f570f085a3e6b58a56bdca/dp_policy/experiments.py#L22-L59" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def titlei_funding(
    allocator: Allocator,
    inputs: pd.DataFrame,
    mechanism: Mechanism,
    sppe: pd.DataFrame,
    normalize: bool = True,
    allocator_kwargs: dict = {},
    sampling_kwargs: dict = {},
    **grants_kwargs
):
    &#34;&#34;&#34;Allocate Title I funding.

    Args:
        allocator (Allocator): The allocator to use.
        inputs (pd.DataFrame): The necessary inputs for the allocator -
            usually the SAIPE - by district.
        mechanism (Mechanism): The randomization mechanism to use.
        sppe (pd.DataFrame): State per-pupil education data.
        normalize (bool, optional): Whether to normalize the authorization
            amounts. Defaults to True.
        allocator_kwargs (dict, optional): Parameters for the allocator.
            Defaults to {}.
        sampling_kwargs (dict, optional): Parameters for the sampling
            mechanism. Defaults to {}.

    Returns:
        pd.DataFrame: Returns input dataframe with grant allocations under
            ground truth, sampling, and privacy randomization.
    &#34;&#34;&#34;
    alloc = allocator(
        data(
            inputs, mechanism, sppe,
            sampling_kwargs=sampling_kwargs,
            **grants_kwargs
        ),
        **allocator_kwargs
    )
    return alloc.allocations(normalize=normalize)</code></pre>
</details>
</dd>
<dt id="dp_policy.experiments.titlei_grid"><code class="name flex">
<span>def <span class="ident">titlei_grid</span></span>(<span>inputs: pandas.core.frame.DataFrame, mech: <a title="dp_policy.titlei.mechanisms.Mechanism" href="titlei/mechanisms.html#dp_policy.titlei.mechanisms.Mechanism">Mechanism</a>, eps: list = [0.001, 0.027825594022071243, 0.774263682681127, 21.54434690031882, 599.4842503189409, 16681.005372000593, 464158.8833612772, 12915496.650148828, 359381366.3804626, 10000000000.0, 2.52], delta: list = [0.0], trials: int = 100, mech_kwargs: dict = {}, auth: bool = False, allocator_kwargs: dict = {}, sampling_kwargs: dict = {}, verbose: bool = True, print_results: list = [2.52, 0.1], plot_results: bool = False, alpha: float = 0.05, results: pandas.core.frame.DataFrame = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Run many trials of Title I process under different privacy parameters.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>inputs</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>The necessary inputs for the allocator -
usually the SAIPE - by district.</dd>
<dt><strong><code>mech</code></strong> :&ensp;<code>Mechanism</code></dt>
<dd>The randomization mechanism to use.</dd>
<dt><strong><code>eps</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>Values of epsilon to try. Defaults to
<code>list(np.logspace(-3, 10, num=10))+[2.52]</code>.</dd>
<dt><strong><code>delta</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>Values of delta to try. Defaults to [0.0].</dd>
<dt><strong><code>trials</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of trials to run for each parameter
combo. Defaults to 100.</dd>
<dt><strong><code>mech_kwargs</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Parameters for the randomization
mechanism. Defaults to {}.</dd>
<dt><strong><code>auth</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to use the raw authorization amounts.
Defaults to False.</dd>
<dt><strong><code>allocator_kwargs</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Parameters for the allocator.
Defaults to {}.</dd>
<dt><strong><code>sampling_kwargs</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Parameters for the sampling
mechanism. Defaults to {}.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Defaults to True.</dd>
<dt><strong><code>print_results</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>Which values of epsilon to print
results for. Defaults to [2.52, 0.1].</dd>
<dt><strong><code>plot_results</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to plot results. Defaults to
False.</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Confidence level for confidence bands.
Defaults to 0.05.</dd>
<dt><strong><code>results</code></strong> :&ensp;<code>pd.DataFrame</code>, optional</dt>
<dd>Pre-computed results to plot. If
provided, will skip grid calculation. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>Results grid.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/0a16f5ad99bbed9ce1f570f085a3e6b58a56bdca/dp_policy/experiments.py#L62-L244" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def titlei_grid(
    inputs: pd.DataFrame,
    mech: Mechanism,
    eps: list = list(np.logspace(-3, 10, num=10)) + [2.52],
    delta: list = [0.0],
    trials: int = 100,
    mech_kwargs: dict = {},
    auth: bool = False,
    allocator_kwargs: dict = {},
    sampling_kwargs: dict = {},
    verbose: bool = True,
    print_results: list = [2.52, 0.1],
    plot_results: bool = False,
    alpha: float = 0.05,
    results: pd.DataFrame = None
):
    &#34;&#34;&#34;Run many trials of Title I process under different privacy parameters.

    Args:
        inputs (pd.DataFrame): The necessary inputs for the allocator -
            usually the SAIPE - by district.
        mech (Mechanism): The randomization mechanism to use.
        eps (list, optional): Values of epsilon to try. Defaults to
            `list(np.logspace(-3, 10, num=10))+[2.52]`.
        delta (list, optional): Values of delta to try. Defaults to [0.0].
        trials (int, optional): Number of trials to run for each parameter
            combo. Defaults to 100.
        mech_kwargs (dict, optional): Parameters for the randomization
            mechanism. Defaults to {}.
        auth (bool, optional): Whether to use the raw authorization amounts.
            Defaults to False.
        allocator_kwargs (dict, optional): Parameters for the allocator.
            Defaults to {}.
        sampling_kwargs (dict, optional): Parameters for the sampling
            mechanism. Defaults to {}.
        verbose (bool, optional): Defaults to True.
        print_results (list, optional): Which values of epsilon to print
            results for. Defaults to [2.52, 0.1].
        plot_results (bool, optional): Whether to plot results. Defaults to
            False.
        alpha (float, optional): Confidence level for confidence bands.
            Defaults to 0.05.
        results (pd.DataFrame, optional): Pre-computed results to plot. If
            provided, will skip grid calculation. Defaults to None.

    Returns:
        pd.DataFrame: Results grid.
    &#34;&#34;&#34;
    if results is None:
        allocations = []
        thresholder = allocator_kwargs.get(&#39;thresholder&#39;)
        if verbose:
            print(f&#34;{len(eps)*len(delta)*trials} iters:&#34;)
        for trial in tqdm(range(trials), desc=&#39;trial&#39;, disable=(not verbose)):
            for d in tqdm(delta, desc=&#39;delta&#39;, leave=False, disable=True):
                for e in tqdm(eps, desc=&#39;eps&#39;, leave=False, disable=True):
                    mechanism = mech(e, d, **mech_kwargs)
                    sppe = get_sppe(os.path.join(
                        config.root,
                        &#34;data/sppe18.xlsx&#34;
                    ))
                    if thresholder is not None and isinstance(
                            thresholder, PastThresholder
                    ):
                        thresholder.set_prior_estimates(
                            mechanism,
                            sppe,
                            verbose=False
                        )
                    allocations.append(titlei_funding(
                        SonnenbergAuthorizer,
                        inputs,
                        mechanism,
                        sppe,
                        allocator_kwargs=allocator_kwargs,
                        sampling_kwargs=sampling_kwargs,
                        verbose=False,  # too noisy for a grid search
                        normalize=(not auth)
                    ))
        results = pd.concat(
            allocations, axis=0,
            keys=itertools.product(range(trials), delta, eps),
            names=[
                &#34;trial&#34;, &#34;delta&#34;, &#34;epsilon&#34;
            ] + list(allocations[-1].index.names)
        )

    if print_results:
        prefixes = [&#34;est&#34;, &#34;dp&#34;, &#34;dpest&#34;]

        for e, alloc in results.groupby(&#34;epsilon&#34;):
            if e in print_results:
                print(f&#34;--- eps={e} ---&#34;)
                data_error = alloc[&#34;est_children_eligible&#34;] \
                    - alloc[&#34;true_children_eligible&#34;]
                dp_error = alloc[&#34;dpest_children_eligible&#34;] \
                    - alloc[&#34;est_children_eligible&#34;]
                s = 0.5
                plt.scatter(
                    alloc[&#34;true_children_eligible&#34;], data_error,
                    s, label=&#34;data&#34;
                )
                plt.scatter(
                    alloc[&#34;true_children_eligible&#34;], dp_error,
                    s, label=&#34;dp&#34;
                )
                plt.legend()
                plt.xlabel(&#34;# children in poverty&#34;)
                plt.ylabel(&#34;Noise&#34;)
                plt.show()

                plt.scatter(
                    alloc[&#34;true_children_eligible&#34;],
                    data_error/alloc[&#34;true_children_eligible&#34;],
                    s, label=&#34;data&#34;
                )
                plt.scatter(
                    alloc[&#34;true_children_eligible&#34;],
                    dp_error/alloc[&#34;true_children_eligible&#34;],
                    s, label=&#34;dp&#34;
                )
                plt.legend()
                plt.xlabel(&#34;# children in poverty&#34;)
                plt.ylabel(&#34;Noise per child in poverty&#34;)
                plt.show()

        for prefix in prefixes:
            print(&#34;##&#34;, prefix)
            for e, alloc in results.groupby(&#34;epsilon&#34;):
                for grant_type in (
                    &#34;basic&#34;, &#34;concentration&#34;, &#34;targeted&#34;, &#34;total&#34;
                ):
                    if e in print_results:
                        error = alloc[f&#34;{prefix}_grant_{grant_type}&#34;] \
                            - alloc[f&#34;true_grant_{grant_type}&#34;]
                        print(f&#34;## {grant_type} grants - eps={e} ##&#34;)
                        misalloc_statistics(
                            error,
                            allocations=alloc,
                            grant_type=grant_type
                        )

            if plot_results:
                trials = len(np.unique(
                    results.index.get_level_values(&#34;trial&#34;)
                ))

                grant_type = &#34;total&#34;

                error = results[f&#34;{prefix}_grant_{grant_type}&#34;] \
                    - results[f&#34;true_grant_{grant_type}&#34;]
                print(error.shape)
                rmse = np.sqrt(error.pow(2).groupby(
                    [&#34;epsilon&#34;, &#34;trial&#34;]
                ).mean())
                print(rmse)
                mse = {
                    &#39;mean&#39;: rmse.groupby(&#34;epsilon&#34;).mean(),
                    &#39;lower&#39;: rmse.groupby(&#34;epsilon&#34;).quantile(alpha/2),
                    &#39;upper&#39;: rmse.groupby(&#34;epsilon&#34;).quantile(1-alpha/2)
                }
                eps = mse[&#39;mean&#39;].index
                plt.plot(eps, mse[&#39;mean&#39;])
                plt.fill_between(
                    eps, mse[&#39;lower&#39;], mse[&#39;upper&#39;],
                    color=&#39;gray&#39;, alpha=0.25
                )
                ax = plt.gca()
                ax.set_xscale(&#39;log&#39;)
                plt.xlabel(&#34;Epsilon&#34;)
                plt.ylabel(
                    f&#34;Avg. RMSE in {grant_type} grants over {trials} trials&#34;
                )
                plt.savefig(
                    os.path.join(
                        config.root,
                        &#34;plots/robustness/eps_sensitivity_frontier.png&#34;
                    ),
                    dpi=300
                )
                plt.show()

    return results</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dp_policy.experiments.Baseline"><code class="flex name class">
<span>class <span class="ident">Baseline</span></span>
<span>(</span><span>name: str, baseline: Union[str, pandas.core.frame.DataFrame] = 'cached', year: int = 2021, trials: int = 1000, eps: List[float] = [0.1], delta: List[float] = [0.0])</span>
</code></dt>
<dd>
<div class="desc"><p>Baseline condition only.</p>
<p>Initialize experiment and set baseline.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Experiment name.</dd>
<dt><strong><code>baseline</code></strong> :&ensp;<code>Union[str, pd.DataFrame]</code>, optional</dt>
<dd>What baseline
(control) results to use. Defaults to "cached".</dd>
<dt><strong><code>year</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>What year to get inputs for. Defaults to
2021.</dd>
<dt><strong><code>trials</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of trials to run for each condition.
Defaults to 1000.</dd>
<dt><strong><code>eps</code></strong> :&ensp;<code>List[float]</code>, optional</dt>
<dd>Values of epsilon to try. Defaults to
[0.1].</dd>
<dt><strong><code>delta</code></strong> :&ensp;<code>List[float]</code>, optional</dt>
<dd>Values of delta to try. Defaults to
[0.0].</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/0a16f5ad99bbed9ce1f570f085a3e6b58a56bdca/dp_policy/experiments.py#L362-L368" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Baseline(Experiment):
    &#34;&#34;&#34;Baseline condition only.
    &#34;&#34;&#34;
    def _get_treatments(self):
        return {
            &#39;baseline&#39;: self.baseline
        }</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></b></code>:
<ul class="hlist">
<li><code><a title="dp_policy.experiments.Experiment.discrimination_join" href="#dp_policy.experiments.Experiment.discrimination_join">discrimination_join</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.get_experiment" href="#dp_policy.experiments.Experiment.get_experiment">get_experiment</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.plot" href="#dp_policy.experiments.Experiment.plot">plot</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.run" href="#dp_policy.experiments.Experiment.run">run</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="dp_policy.experiments.Budget"><code class="flex name class">
<span>class <span class="ident">Budget</span></span>
<span>(</span><span>name: str, baseline: Union[str, pandas.core.frame.DataFrame] = 'cached', year: int = 2021, trials: int = 1000, eps: List[float] = [0.1], delta: List[float] = [0.0])</span>
</code></dt>
<dd>
<div class="desc"><p>Budget experiments.</p>
<p>Initialize experiment and set baseline.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Experiment name.</dd>
<dt><strong><code>baseline</code></strong> :&ensp;<code>Union[str, pd.DataFrame]</code>, optional</dt>
<dd>What baseline
(control) results to use. Defaults to "cached".</dd>
<dt><strong><code>year</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>What year to get inputs for. Defaults to
2021.</dd>
<dt><strong><code>trials</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of trials to run for each condition.
Defaults to 1000.</dd>
<dt><strong><code>eps</code></strong> :&ensp;<code>List[float]</code>, optional</dt>
<dd>Values of epsilon to try. Defaults to
[0.1].</dd>
<dt><strong><code>delta</code></strong> :&ensp;<code>List[float]</code>, optional</dt>
<dd>Values of delta to try. Defaults to
[0.0].</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/0a16f5ad99bbed9ce1f570f085a3e6b58a56bdca/dp_policy/experiments.py#L570-L627" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Budget(Experiment):
    &#34;&#34;&#34;Budget experiments.
    &#34;&#34;&#34;
    def _get_treatments(self):
        if len(self.eps) &gt; 0:
            print(&#34;[WARN] Using first value of epsilon for budget calcs.&#34;)

        e = self.eps[0]
        alpha = 0.05
        test = self.baseline.loc[pd.IndexSlice[:, 0.0, e, :, :], :]

        budgets = {
            &#34;Biden proposal&#34;: 2e10
        }
        for name, prefixes in {
            &#34;+ loss&#34;: (&#34;dpest&#34;, &#34;true&#34;),
            # &#34;+ marginal loss (DP)&#34;: (&#34;dpest&#34;, &#34;est&#34;),
            # &#34;+ loss (data error)&#34;: (&#34;est&#34;, &#34;true&#34;)
        }.items():
            error = test[f&#34;{prefixes[1]}_grant_total&#34;] \
                - test[f&#34;{prefixes[0]}_grant_total&#34;]
            err_grouped = error.groupby(
                [&#34;State FIPS Code&#34;, &#34;District ID&#34;]
            )
            exp_error = err_grouped.mean()

            budgets[name] = exp_error[exp_error &lt; 0].abs().sum()

            if prefixes == (&#34;dpest&#34;, &#34;true&#34;):
                # how much money to remove alpha quantile loss?
                quantile = err_grouped.quantile(alpha)
                budgets[f&#34;+ {(alpha)*100}% quant. loss&#34;] = \
                    quantile[quantile &lt; 0].abs().sum()

                # how much money to cover all misallocated dollars?
                # budgets[f&#34;+ exp. misalloc.&#34;] = exp_error.abs().sum()

        budgets = {&#34;{} (${:.1e})&#34;.format(k, v): v for k, v in budgets.items()}

        usual_budget = self.saipe[&#34;official_total_alloc&#34;]\
            .groupby([&#34;State FIPS Code&#34;, &#34;District ID&#34;]).first().sum()
        print(&#34;baseline budget: {:.1e}&#34;.format(usual_budget))
        print(budgets)

        treatments = {
            name: titlei_grid(
                self.saipe, Laplace,
                eps=[e], delta=self.delta,
                trials=self.trials, print_results=False,
                allocator_kwargs={
                    &#39;appropriation&#39;: round(budget + usual_budget, 2)
                }
            ) for name, budget in budgets.items()
        }
        match_true(self.baseline, list(treatments.values()))
        treatments[&#34;FY2019 appropriation (baseline)&#34;] = test

        return treatments</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></b></code>:
<ul class="hlist">
<li><code><a title="dp_policy.experiments.Experiment.discrimination_join" href="#dp_policy.experiments.Experiment.discrimination_join">discrimination_join</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.get_experiment" href="#dp_policy.experiments.Experiment.get_experiment">get_experiment</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.plot" href="#dp_policy.experiments.Experiment.plot">plot</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.run" href="#dp_policy.experiments.Experiment.run">run</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="dp_policy.experiments.Epsilon"><code class="flex name class">
<span>class <span class="ident">Epsilon</span></span>
<span>(</span><span>name: str, baseline: Union[str, pandas.core.frame.DataFrame] = 'cached', year: int = 2021, trials: int = 1000, eps: List[float] = [0.1], delta: List[float] = [0.0])</span>
</code></dt>
<dd>
<div class="desc"><p>Privacy parameter experiments.</p>
<p>Initialize experiment and set baseline.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Experiment name.</dd>
<dt><strong><code>baseline</code></strong> :&ensp;<code>Union[str, pd.DataFrame]</code>, optional</dt>
<dd>What baseline
(control) results to use. Defaults to "cached".</dd>
<dt><strong><code>year</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>What year to get inputs for. Defaults to
2021.</dd>
<dt><strong><code>trials</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of trials to run for each condition.
Defaults to 1000.</dd>
<dt><strong><code>eps</code></strong> :&ensp;<code>List[float]</code>, optional</dt>
<dd>Values of epsilon to try. Defaults to
[0.1].</dd>
<dt><strong><code>delta</code></strong> :&ensp;<code>List[float]</code>, optional</dt>
<dd>Values of delta to try. Defaults to
[0.0].</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/0a16f5ad99bbed9ce1f570f085a3e6b58a56bdca/dp_policy/experiments.py#L630-L648" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Epsilon(Experiment):
    &#34;&#34;&#34;Privacy parameter experiments.
    &#34;&#34;&#34;
    def _get_treatments(self):
        return {
            e: titlei_grid(
                self.saipe, Laplace,
                eps=[e], delta=self.delta,
                trials=self.trials, print_results=False
            ) if e not in self.eps
            else self.baseline.loc[pd.IndexSlice[:, 0.0, e, :, :], :].copy()
            for e in [1e-3, 1e-2, 1e-1, 1, 10, 30]
        }

    def discrimination_join(self):
        return super().discrimination_join(epsilon=None)

    def plot(self):
        return super().plot(epsilon=None)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></b></code>:
<ul class="hlist">
<li><code><a title="dp_policy.experiments.Experiment.discrimination_join" href="#dp_policy.experiments.Experiment.discrimination_join">discrimination_join</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.get_experiment" href="#dp_policy.experiments.Experiment.get_experiment">get_experiment</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.plot" href="#dp_policy.experiments.Experiment.plot">plot</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.run" href="#dp_policy.experiments.Experiment.run">run</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="dp_policy.experiments.Experiment"><code class="flex name class">
<span>class <span class="ident">Experiment</span></span>
<span>(</span><span>name: str, baseline: Union[str, pandas.core.frame.DataFrame] = 'cached', year: int = 2021, trials: int = 1000, eps: List[float] = [0.1], delta: List[float] = [0.0])</span>
</code></dt>
<dd>
<div class="desc"><p>Handles running and setting experiments.</p>
<p>Initialize experiment and set baseline.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Experiment name.</dd>
<dt><strong><code>baseline</code></strong> :&ensp;<code>Union[str, pd.DataFrame]</code>, optional</dt>
<dd>What baseline
(control) results to use. Defaults to "cached".</dd>
<dt><strong><code>year</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>What year to get inputs for. Defaults to
2021.</dd>
<dt><strong><code>trials</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of trials to run for each condition.
Defaults to 1000.</dd>
<dt><strong><code>eps</code></strong> :&ensp;<code>List[float]</code>, optional</dt>
<dd>Values of epsilon to try. Defaults to
[0.1].</dd>
<dt><strong><code>delta</code></strong> :&ensp;<code>List[float]</code>, optional</dt>
<dd>Values of delta to try. Defaults to
[0.0].</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/0a16f5ad99bbed9ce1f570f085a3e6b58a56bdca/dp_policy/experiments.py#L247-L359" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Experiment:
    &#34;&#34;&#34;Handles running and setting experiments.
    &#34;&#34;&#34;
    def __init__(
        self,
        name: str,
        baseline: Union[str, pd.DataFrame] = &#34;cached&#34;,
        year: int = 2021,
        trials: int = 1000,
        eps: List[float] = [0.1],
        delta: List[float] = [0.0]
    ):
        &#34;&#34;&#34;Initialize experiment and set baseline.

        Args:
            name (str): Experiment name.
            baseline (Union[str, pd.DataFrame], optional): What baseline
                (control) results to use. Defaults to &#34;cached&#34;.
            year (int, optional): What year to get inputs for. Defaults to
                2021.
            trials (int, optional): Number of trials to run for each condition.
                Defaults to 1000.
            eps (List[float], optional): Values of epsilon to try. Defaults to
                [0.1].
            delta (List[float], optional): Values of delta to try. Defaults to
                [0.0].
        &#34;&#34;&#34;
        self.name = name
        self.trials = trials
        self.eps = eps
        self.delta = delta
        self.saipe = get_inputs(year)

        if str(baseline) == &#34;cached&#34;:
            print(&#34;Using cached baseline...&#34;)
            try:
                self.baseline = load_treatments(&#34;baseline&#34;)[&#39;baseline&#39;]
            except FileNotFoundError:
                print(&#34;[WARN] Could not find cached baseline, generating.&#34;)
                self._generate_baseline()
        elif baseline is None:
            print(&#34;Generating baseline...&#34;)
            self._generate_baseline()
        else:
            print(&#34;Using given baseline...&#34;)
            self.baseline = baseline

    def _generate_baseline(self):
        &#34;&#34;&#34;Generate the control condition. Defaults to normal Laplace
            mechanism with no special allocation parameters.
        &#34;&#34;&#34;
        self.baseline = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps, delta=self.delta,
            trials=self.trials,
            print_results=False,
            allocator_kwargs={&#39;verbose&#39;: False}
        )
        save_treatments({&#39;baseline&#39;: self.baseline}, &#34;baseline&#34;)
        discrimination_treatments_join(&#34;baseline&#34;)

    def run(self):
        &#34;&#34;&#34;Run the experiment, save results, and create joined covariate file.
        &#34;&#34;&#34;
        treatments = self._get_treatments()
        save_treatments(treatments, self.name)
        self.discrimination_join()

    def _get_treatments(self):
        &#34;&#34;&#34;Generate the treatment results.
        &#34;&#34;&#34;
        raise NotImplementedError

    def discrimination_join(self, **join_kwargs):
        &#34;&#34;&#34;Join the results to demographic covariates and save.
        &#34;&#34;&#34;
        discrimination_treatments_join(self.name, **join_kwargs)

    def plot(self, **kwargs):
        &#34;&#34;&#34;Print and plot the results, comparing treatments.
        &#34;&#34;&#34;
        treatments = load_treatments(self.name)
        compare_treatments(treatments, experiment_name=self.name, **kwargs)

    @staticmethod
    def get_experiment(
        name: str,
        *args, **kwargs
    ):
        &#34;&#34;&#34;Factory class for generating experiment object from name.

        Args:
            name (str): Experiment name to fetch. Options include &#34;baseline&#34;,
                &#34;hold_harmless&#34;, &#34;post_processing&#34;, &#34;thresholds&#34;, &#34;epsilon&#34;,
                &#34;moving_average&#34;, &#34;budget&#34;, &#34;sampling&#34;.

        Returns:
            Experiment: The experiment object.
        &#34;&#34;&#34;
        experiments = {
            &#39;baseline&#39;: Baseline,
            &#39;hold_harmless&#39;: HoldHarmless,
            &#39;post_processing&#39;: PostProcessing,
            &#39;thresholds&#39;: Thresholds,
            &#39;epsilon&#39;: Epsilon,
            &#39;moving_average&#39;: MovingAverage,
            &#39;budget&#39;: Budget,
            &#39;sampling&#39;: Sampling
        }
        Exp = experiments.get(name)
        if Exp is None:
            raise ValueError(f&#34;{name} not a supported experiment name.&#34;)
        return Exp(name, *args, **kwargs)</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Baseline" href="#dp_policy.experiments.Baseline">Baseline</a></li>
<li><a title="dp_policy.experiments.Budget" href="#dp_policy.experiments.Budget">Budget</a></li>
<li><a title="dp_policy.experiments.Epsilon" href="#dp_policy.experiments.Epsilon">Epsilon</a></li>
<li><a title="dp_policy.experiments.HoldHarmless" href="#dp_policy.experiments.HoldHarmless">HoldHarmless</a></li>
<li><a title="dp_policy.experiments.MovingAverage" href="#dp_policy.experiments.MovingAverage">MovingAverage</a></li>
<li><a title="dp_policy.experiments.PostProcessing" href="#dp_policy.experiments.PostProcessing">PostProcessing</a></li>
<li><a title="dp_policy.experiments.Sampling" href="#dp_policy.experiments.Sampling">Sampling</a></li>
<li><a title="dp_policy.experiments.Thresholds" href="#dp_policy.experiments.Thresholds">Thresholds</a></li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="dp_policy.experiments.Experiment.get_experiment"><code class="name flex">
<span>def <span class="ident">get_experiment</span></span>(<span>name: str, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Factory class for generating experiment object from name.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Experiment name to fetch. Options include "baseline",
"hold_harmless", "post_processing", "thresholds", "epsilon",
"moving_average", "budget", "sampling".</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></code></dt>
<dd>The experiment object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/0a16f5ad99bbed9ce1f570f085a3e6b58a56bdca/dp_policy/experiments.py#L331-L359" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@staticmethod
def get_experiment(
    name: str,
    *args, **kwargs
):
    &#34;&#34;&#34;Factory class for generating experiment object from name.

    Args:
        name (str): Experiment name to fetch. Options include &#34;baseline&#34;,
            &#34;hold_harmless&#34;, &#34;post_processing&#34;, &#34;thresholds&#34;, &#34;epsilon&#34;,
            &#34;moving_average&#34;, &#34;budget&#34;, &#34;sampling&#34;.

    Returns:
        Experiment: The experiment object.
    &#34;&#34;&#34;
    experiments = {
        &#39;baseline&#39;: Baseline,
        &#39;hold_harmless&#39;: HoldHarmless,
        &#39;post_processing&#39;: PostProcessing,
        &#39;thresholds&#39;: Thresholds,
        &#39;epsilon&#39;: Epsilon,
        &#39;moving_average&#39;: MovingAverage,
        &#39;budget&#39;: Budget,
        &#39;sampling&#39;: Sampling
    }
    Exp = experiments.get(name)
    if Exp is None:
        raise ValueError(f&#34;{name} not a supported experiment name.&#34;)
    return Exp(name, *args, **kwargs)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dp_policy.experiments.Experiment.discrimination_join"><code class="name flex">
<span>def <span class="ident">discrimination_join</span></span>(<span>self, **join_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Join the results to demographic covariates and save.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/0a16f5ad99bbed9ce1f570f085a3e6b58a56bdca/dp_policy/experiments.py#L320-L323" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def discrimination_join(self, **join_kwargs):
    &#34;&#34;&#34;Join the results to demographic covariates and save.
    &#34;&#34;&#34;
    discrimination_treatments_join(self.name, **join_kwargs)</code></pre>
</details>
</dd>
<dt id="dp_policy.experiments.Experiment.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Print and plot the results, comparing treatments.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/0a16f5ad99bbed9ce1f570f085a3e6b58a56bdca/dp_policy/experiments.py#L325-L329" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def plot(self, **kwargs):
    &#34;&#34;&#34;Print and plot the results, comparing treatments.
    &#34;&#34;&#34;
    treatments = load_treatments(self.name)
    compare_treatments(treatments, experiment_name=self.name, **kwargs)</code></pre>
</details>
</dd>
<dt id="dp_policy.experiments.Experiment.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Run the experiment, save results, and create joined covariate file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/0a16f5ad99bbed9ce1f570f085a3e6b58a56bdca/dp_policy/experiments.py#L308-L313" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def run(self):
    &#34;&#34;&#34;Run the experiment, save results, and create joined covariate file.
    &#34;&#34;&#34;
    treatments = self._get_treatments()
    save_treatments(treatments, self.name)
    self.discrimination_join()</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dp_policy.experiments.HoldHarmless"><code class="flex name class">
<span>class <span class="ident">HoldHarmless</span></span>
<span>(</span><span>name: str, baseline: Union[str, pandas.core.frame.DataFrame] = 'cached', year: int = 2021, trials: int = 1000, eps: List[float] = [0.1], delta: List[float] = [0.0])</span>
</code></dt>
<dd>
<div class="desc"><p>Hold harmless and state minimum provisions.</p>
<p>Initialize experiment and set baseline.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Experiment name.</dd>
<dt><strong><code>baseline</code></strong> :&ensp;<code>Union[str, pd.DataFrame]</code>, optional</dt>
<dd>What baseline
(control) results to use. Defaults to "cached".</dd>
<dt><strong><code>year</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>What year to get inputs for. Defaults to
2021.</dd>
<dt><strong><code>trials</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of trials to run for each condition.
Defaults to 1000.</dd>
<dt><strong><code>eps</code></strong> :&ensp;<code>List[float]</code>, optional</dt>
<dd>Values of epsilon to try. Defaults to
[0.1].</dd>
<dt><strong><code>delta</code></strong> :&ensp;<code>List[float]</code>, optional</dt>
<dd>Values of delta to try. Defaults to
[0.0].</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/0a16f5ad99bbed9ce1f570f085a3e6b58a56bdca/dp_policy/experiments.py#L371-L405" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class HoldHarmless(Experiment):
    &#34;&#34;&#34;Hold harmless and state minimum provisions.
    &#34;&#34;&#34;
    def _get_treatments(self):
        hold_harmless = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps, delta=self.delta,
            trials=self.trials, print_results=False,
            allocator_kwargs={&#39;hold_harmless&#39;: True}
        )
        state_minimum = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps, delta=self.delta,
            trials=self.trials, print_results=False,
            allocator_kwargs={&#39;state_minimum&#39;: True}
        )
        both = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps, delta=self.delta,
            trials=self.trials, print_results=False,
            allocator_kwargs={
                &#39;hold_harmless&#39;: True,
                &#39;state_minimum&#39;: True
            }
        )
        # ground truths are the same
        match_true(self.baseline, [hold_harmless, state_minimum, both])

        # save treatments to file for later
        return {
            &#39;No provisions (baseline)&#39;: self.baseline,
            &#39;Hold harmless only&#39;: hold_harmless,
            &#39;State minimum only&#39;: state_minimum,
            &#39;Both provisions&#39;: both
        }</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></b></code>:
<ul class="hlist">
<li><code><a title="dp_policy.experiments.Experiment.discrimination_join" href="#dp_policy.experiments.Experiment.discrimination_join">discrimination_join</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.get_experiment" href="#dp_policy.experiments.Experiment.get_experiment">get_experiment</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.plot" href="#dp_policy.experiments.Experiment.plot">plot</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.run" href="#dp_policy.experiments.Experiment.run">run</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="dp_policy.experiments.MovingAverage"><code class="flex name class">
<span>class <span class="ident">MovingAverage</span></span>
<span>(</span><span>name: str, truth: str = 'average', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Moving average inputs, with multiple lag conditions.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>truth</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Baseline strategy to use. "average" uses
the 5-year average as the baseline. Defaults to "average".</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd><em>description</em></dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/0a16f5ad99bbed9ce1f570f085a3e6b58a56bdca/dp_policy/experiments.py#L443-L484" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class MovingAverage(Experiment):
    &#34;&#34;&#34;Moving average inputs, with multiple lag conditions.
    &#34;&#34;&#34;
    def __init__(
        self,
        name: str,
        truth: str = &#34;average&#34;,
        **kwargs
    ):
        &#34;&#34;&#34;
        Args:
            truth (str, optional): Baseline strategy to use. &#34;average&#34; uses
                the 5-year average as the baseline. Defaults to &#34;average&#34;.

        Raises:
            Exception: _description_
        &#34;&#34;&#34;
        if truth != &#34;average&#34;:
            raise Exception(
                &#34;Not supporting truth values other than `average`.&#34;
            )
        self.truth = truth
        super().__init__(f&#34;{name}_truth={truth}&#34;, **kwargs)

    def _get_treatments(self):
        single_year = self.baseline
        averaged = [
            titlei_grid(
                get_inputs(2021, avg_lag=i+1),
                Laplace,
                eps=self.eps,
                delta=self.delta,
                trials=self.trials,
                print_results=False
            )
            for i in range(4)
        ]
        match_true(averaged[-1], [single_year] + averaged[:-1])
        return {
            &#39;Lag 0&#39;: single_year,
            **{f&#34;Lag {i+1}&#34;: a for i, a in enumerate(averaged)}
        }</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></b></code>:
<ul class="hlist">
<li><code><a title="dp_policy.experiments.Experiment.discrimination_join" href="#dp_policy.experiments.Experiment.discrimination_join">discrimination_join</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.get_experiment" href="#dp_policy.experiments.Experiment.get_experiment">get_experiment</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.plot" href="#dp_policy.experiments.Experiment.plot">plot</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.run" href="#dp_policy.experiments.Experiment.run">run</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="dp_policy.experiments.PostProcessing"><code class="flex name class">
<span>class <span class="ident">PostProcessing</span></span>
<span>(</span><span>name: str, baseline: Union[str, pandas.core.frame.DataFrame] = 'cached', year: int = 2021, trials: int = 1000, eps: List[float] = [0.1], delta: List[float] = [0.0])</span>
</code></dt>
<dd>
<div class="desc"><p>Post-processing variations: none, clipping, and clipping + rounding.</p>
<p>Initialize experiment and set baseline.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Experiment name.</dd>
<dt><strong><code>baseline</code></strong> :&ensp;<code>Union[str, pd.DataFrame]</code>, optional</dt>
<dd>What baseline
(control) results to use. Defaults to "cached".</dd>
<dt><strong><code>year</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>What year to get inputs for. Defaults to
2021.</dd>
<dt><strong><code>trials</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of trials to run for each condition.
Defaults to 1000.</dd>
<dt><strong><code>eps</code></strong> :&ensp;<code>List[float]</code>, optional</dt>
<dd>Values of epsilon to try. Defaults to
[0.1].</dd>
<dt><strong><code>delta</code></strong> :&ensp;<code>List[float]</code>, optional</dt>
<dd>Values of delta to try. Defaults to
[0.0].</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/0a16f5ad99bbed9ce1f570f085a3e6b58a56bdca/dp_policy/experiments.py#L408-L440" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class PostProcessing(Experiment):
    &#34;&#34;&#34;Post-processing variations: none, clipping, and clipping + rounding.
    &#34;&#34;&#34;
    def _get_treatments(self):
        none = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            mech_kwargs=dict(
                clip=False,
                round=False
            ),
            print_results=False
        )
        clipping = self.baseline
        rounding = titlei_grid(
            self.saipe, Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            mech_kwargs=dict(
                clip=True,
                round=True
            ),
            print_results=False
        )
        match_true(self.baseline, [none, rounding])
        return {
            &#39;None&#39;: none,
            &#39;Clipping (baseline)&#39;: clipping,
            &#39;Clipping + Rounding&#39;: rounding
        }</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></b></code>:
<ul class="hlist">
<li><code><a title="dp_policy.experiments.Experiment.discrimination_join" href="#dp_policy.experiments.Experiment.discrimination_join">discrimination_join</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.get_experiment" href="#dp_policy.experiments.Experiment.get_experiment">get_experiment</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.plot" href="#dp_policy.experiments.Experiment.plot">plot</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.run" href="#dp_policy.experiments.Experiment.run">run</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="dp_policy.experiments.Sampling"><code class="flex name class">
<span>class <span class="ident">Sampling</span></span>
<span>(</span><span>name: str, baseline: Union[str, pandas.core.frame.DataFrame] = 'cached', year: int = 2021, trials: int = 1000, eps: List[float] = [0.1], delta: List[float] = [0.0])</span>
</code></dt>
<dd>
<div class="desc"><p>Sampling error experiments.</p>
<p>Initialize experiment and set baseline.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Experiment name.</dd>
<dt><strong><code>baseline</code></strong> :&ensp;<code>Union[str, pd.DataFrame]</code>, optional</dt>
<dd>What baseline
(control) results to use. Defaults to "cached".</dd>
<dt><strong><code>year</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>What year to get inputs for. Defaults to
2021.</dd>
<dt><strong><code>trials</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of trials to run for each condition.
Defaults to 1000.</dd>
<dt><strong><code>eps</code></strong> :&ensp;<code>List[float]</code>, optional</dt>
<dd>Values of epsilon to try. Defaults to
[0.1].</dd>
<dt><strong><code>delta</code></strong> :&ensp;<code>List[float]</code>, optional</dt>
<dd>Values of delta to try. Defaults to
[0.0].</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/0a16f5ad99bbed9ce1f570f085a3e6b58a56bdca/dp_policy/experiments.py#L651-L682" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Sampling(Experiment):
    &#34;&#34;&#34;Sampling error experiments.
    &#34;&#34;&#34;
    def _get_treatments(self):
        gaussian = {
            f&#34;Gaussian ({m})&#34;: titlei_grid(
                self.saipe, Laplace,
                eps=self.eps, delta=self.delta,
                trials=self.trials, print_results=False,
                sampling_kwargs=dict(
                    multiplier=m,
                    distribution=&#34;gaussian&#34;
                )
            )
            for m in [0.5, 0.75, 1, 1.5]
        }
        laplace = {
            f&#34;Laplace ({m})&#34;: titlei_grid(
                self.saipe, Laplace,
                eps=self.eps, delta=self.delta,
                trials=self.trials, print_results=False,
                sampling_kwargs=dict(
                    multiplier=m,
                    distribution=&#34;laplace&#34;
                )
            )
            for m in [0.5, 1, 1.5]
        }
        return {
            **gaussian,
            **laplace
        }</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></b></code>:
<ul class="hlist">
<li><code><a title="dp_policy.experiments.Experiment.discrimination_join" href="#dp_policy.experiments.Experiment.discrimination_join">discrimination_join</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.get_experiment" href="#dp_policy.experiments.Experiment.get_experiment">get_experiment</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.plot" href="#dp_policy.experiments.Experiment.plot">plot</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.run" href="#dp_policy.experiments.Experiment.run">run</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="dp_policy.experiments.Thresholds"><code class="flex name class">
<span>class <span class="ident">Thresholds</span></span>
<span>(</span><span>name: str, baseline: Union[str, pandas.core.frame.DataFrame] = 'cached', year: int = 2021, trials: int = 1000, eps: List[float] = [0.1], delta: List[float] = [0.0])</span>
</code></dt>
<dd>
<div class="desc"><p>Thresholding experiments.</p>
<p>Initialize experiment and set baseline.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Experiment name.</dd>
<dt><strong><code>baseline</code></strong> :&ensp;<code>Union[str, pd.DataFrame]</code>, optional</dt>
<dd>What baseline
(control) results to use. Defaults to "cached".</dd>
<dt><strong><code>year</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>What year to get inputs for. Defaults to
2021.</dd>
<dt><strong><code>trials</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of trials to run for each condition.
Defaults to 1000.</dd>
<dt><strong><code>eps</code></strong> :&ensp;<code>List[float]</code>, optional</dt>
<dd>Values of epsilon to try. Defaults to
[0.1].</dd>
<dt><strong><code>delta</code></strong> :&ensp;<code>List[float]</code>, optional</dt>
<dd>Values of delta to try. Defaults to
[0.0].</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ryansteed/dp-policy/blob/0a16f5ad99bbed9ce1f570f085a3e6b58a56bdca/dp_policy/experiments.py#L487-L567" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Thresholds(Experiment):
    &#34;&#34;&#34;Thresholding experiments.
    &#34;&#34;&#34;
    def _get_treatments(self):
        # hard threshold
        hard = self.baseline

        # use average
        averaged = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: AverageThresholder(2021, 4)
            },
            print_results=False
        )

        # must be ineligible 2x in a row
        repeat2 = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: RepeatThresholder(2021, 1)
            },
            print_results=False
        )

        # must be ineligible 3x in a row
        repeat3 = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: RepeatThresholder(2021, 2)
            },
            print_results=False
        )

        # no threshold
        none = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: DummyThresholder()
            },
            print_results=False
        )

        # moe
        moe_01 = titlei_grid(
            self.saipe,
            Laplace,
            eps=self.eps,
            delta=self.delta,
            trials=self.trials,
            allocator_kwargs={
                &#39;thresholder&#39;: MOEThresholder(alpha=0.1)
            },
            print_results=False
        )

        match_true(hard, [averaged, repeat2, repeat3, none, moe_01])
        return {
            &#39;None&#39;: none,
            &#39;Hard (baseline)&#39;: hard,
            &#39;Averaged&#39;: averaged,
            &#39;Repeated years (2)&#39;: repeat2,
            &#39;Repeated years (3)&#39;: repeat3,
            &#39;Margin of error (90%)&#39;: moe_01
        }</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></b></code>:
<ul class="hlist">
<li><code><a title="dp_policy.experiments.Experiment.discrimination_join" href="#dp_policy.experiments.Experiment.discrimination_join">discrimination_join</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.get_experiment" href="#dp_policy.experiments.Experiment.get_experiment">get_experiment</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.plot" href="#dp_policy.experiments.Experiment.plot">plot</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.run" href="#dp_policy.experiments.Experiment.run">run</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dp_policy" href="index.html">dp_policy</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="dp_policy.experiments.titlei_funding" href="#dp_policy.experiments.titlei_funding">titlei_funding</a></code></li>
<li><code><a title="dp_policy.experiments.titlei_grid" href="#dp_policy.experiments.titlei_grid">titlei_grid</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dp_policy.experiments.Baseline" href="#dp_policy.experiments.Baseline">Baseline</a></code></h4>
</li>
<li>
<h4><code><a title="dp_policy.experiments.Budget" href="#dp_policy.experiments.Budget">Budget</a></code></h4>
</li>
<li>
<h4><code><a title="dp_policy.experiments.Epsilon" href="#dp_policy.experiments.Epsilon">Epsilon</a></code></h4>
</li>
<li>
<h4><code><a title="dp_policy.experiments.Experiment" href="#dp_policy.experiments.Experiment">Experiment</a></code></h4>
<ul class="">
<li><code><a title="dp_policy.experiments.Experiment.discrimination_join" href="#dp_policy.experiments.Experiment.discrimination_join">discrimination_join</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.get_experiment" href="#dp_policy.experiments.Experiment.get_experiment">get_experiment</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.plot" href="#dp_policy.experiments.Experiment.plot">plot</a></code></li>
<li><code><a title="dp_policy.experiments.Experiment.run" href="#dp_policy.experiments.Experiment.run">run</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dp_policy.experiments.HoldHarmless" href="#dp_policy.experiments.HoldHarmless">HoldHarmless</a></code></h4>
</li>
<li>
<h4><code><a title="dp_policy.experiments.MovingAverage" href="#dp_policy.experiments.MovingAverage">MovingAverage</a></code></h4>
</li>
<li>
<h4><code><a title="dp_policy.experiments.PostProcessing" href="#dp_policy.experiments.PostProcessing">PostProcessing</a></code></h4>
</li>
<li>
<h4><code><a title="dp_policy.experiments.Sampling" href="#dp_policy.experiments.Sampling">Sampling</a></code></h4>
</li>
<li>
<h4><code><a title="dp_policy.experiments.Thresholds" href="#dp_policy.experiments.Thresholds">Thresholds</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>